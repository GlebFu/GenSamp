

@online{OvidRandomizedTrial,
  title = {Ovid: {{A Randomized Trial Comparing}} a {{Very Low Carbohydrate Diet}} and a {{Calorie}}-{{Restricted Low Fat Diet}} on {{Body Weight}} and {{Cardiovascular Risk Factors}} in {{Healthy Women}}.},
  url = {http://ovidsp.tx.ovid.com.ezproxy.lib.utexas.edu/sp-3.18.0b/ovidweb.cgi?QS2=434f4e1a73d37e8ce0afc23d6b1080bfc577a52e5fa5564360eeb8238e666c2329a0d3d7dda2b9fd3eaf39bf4e143576316ade9abad0a281dbe666475b0abd5940bc837c245c909f763e393db035a636693925a177dd97042973524cb4d8b9b81eba4de3626f0d83c35b4a99f92746f820667f235dfd05a00ad844032f4c4977cbb3bd12eb1decb3d47f85acdee80400b24b3d51fc6f2432b91ce3e01bd4e4a60688c1e0ba86b6ac3a783a474e794985ca5767ca48ba7280633d9da330752af12bf46660a12adcd0ef0d09ae3f622c20ce32de727c40c1c63f035055836fc7c06c929c79c6e4e74738673d54579d9366b1c617f32833e266d5c0b68fa05c70671cece3378be91dc1a8353eeae6e09c8ea6eea1fe64eb139675f0257da2862aa583b145a5eaf406f32db680eae7e961b7e8e0c9941cb06538d193c129fc0bfc801bb9b64d0efa313b313b30115a8cf2974bbb2da01d757c77f3cc5030b1c6cd1a0caee2d67c2f0b59eca504e35af489ee423b403bc00dfb98807aa5ec244a32d7},
  urldate = {2016-03-23},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\MUBVGDVI\\ovidweb.html}
}


@article{bradleyLowFatLowCarbohydrateWeight2009,
  langid = {english},
  title = {Low-{{Fat Versus Low}}-{{Carbohydrate Weight Reduction Diets Effects}} on {{Weight Loss}}, {{Insulin Resistance}}, and {{Cardiovascular Risk}}: {{A Randomized Control Trial}}},
  volume = {58},
  issn = {0012-1797, 1939-327X},
  url = {http://diabetes.diabetesjournals.org/content/58/12/2741},
  doi = {10.2337/db09-0098},
  shorttitle = {Low-{{Fat Versus Low}}-{{Carbohydrate Weight Reduction Diets Effects}} on {{Weight Loss}}, {{Insulin Resistance}}, and {{Cardiovascular Risk}}},
  abstract = {OBJECTIVE Low-fat hypocaloric diets reduce insulin resistance and prevent type 2 diabetes in those at risk. Low-carbohydrate, high-fat diets are advocated as an alternative, but reciprocal increases in dietary fat may have detrimental effects on insulin resistance and offset the benefits of weight reduction.
RESEARCH DESIGN AND METHODS We investigated a low-fat (20\% fat, 60\% carbohydrate) versus a low-carbohydrate (60\% fat, 20\% carbohydrate) weight reduction diet in 24 overweight/obese subjects ([mean ± SD] BMI 33.6 ± 3.7 kg/m2, aged 39 ± 10 years) in an 8-week randomized controlled trial. All food was weighed and distributed, and intake was calculated to produce a 500 kcal/day energy deficit. Insulin action was assessed by the euglycemic clamp and insulin secretion by meal tolerance test. Body composition, adipokine levels, and vascular compliance by pulse-wave analysis were also measured.
RESULTS Significant weight loss occurred in both groups (P $<$ 0.01), with no difference between groups (P = 0.40). Peripheral glucose uptake increased, but there was no difference between groups (P = 0.28), and suppression of endogenous glucose production was also similar between groups. Meal tolerance–related insulin secretion decreased with weight loss with no difference between groups (P = 0.71). The change in overall systemic arterial stiffness was, however, significantly different between diets (P = 0.04); this reflected a significant decrease in augmentation index following the low-fat diet, compared with a nonsignificant increase within the low-carbohydrate group.
CONCLUSIONS This study demonstrates comparable effects on insulin resistance of low-fat and low-carbohydrate diets independent of macronutrient content. The difference in augmentation index may imply a negative effect of low-carbohydrate diets on vascular risk.},
  number = {12},
  journaltitle = {Diabetes},
  shortjournal = {Diabetes},
  urldate = {2016-03-23},
  date = {2009-01-12},
  pages = {2741-2748},
  author = {Bradley, Una and Spence, Michelle and Courtney, C. Hamish and McKinley, Michelle C. and Ennis, Cieran N. and McCance, David R. and McEneny, Jane and Bell, Patrick M. and Young, Ian S. and Hunter, Steven J.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\WDBVJEE5\\Bradley et al. - 2009 - Low-Fat Versus Low-Carbohydrate Weight Reduction D.pdf;C:\\Users\\Gleb\\Zotero\\storage\\JFAKUJVJ\\2741.html},
  eprinttype = {pmid},
  eprint = {19720791}
}


@article{sackner-bernsteinDietaryInterventionOverweight2015,
  title = {Dietary {{Intervention}} for {{Overweight}} and {{Obese Adults}}: {{Comparison}} of {{Low}}-{{Carbohydrate}} and {{Low}}-{{Fat Diets}}. {{A Meta}}-{{Analysis}}},
  volume = {10},
  issn = {1932-6203},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4618935/},
  doi = {10.1371/journal.pone.0139817},
  shorttitle = {Dietary {{Intervention}} for {{Overweight}} and {{Obese Adults}}},
  abstract = {Background
Reduced calorie, low fat diet is currently recommended diet for overweight and obese adults. Prior data suggest that low carbohydrate diets may also be a viable option for those who are overweight and obese.

Purpose
Compare the effects of low carbohydrate versus low fats diet on weight and atherosclerotic cardiovascular disease risk in overweight and obese patients.

Data Sources
Systematic literature review via PubMed (1966–2014).

Study Selection
Randomized controlled trials with ≥8 weeks follow up, comparing low carbohydrate (≤120gm carbohydrates/day) and low fat diet (≤30\% energy from fat/day).

Data Extraction
Data were extracted and prepared for analysis using double data entry. Prior to identification of candidate publications, the outcomes of change in weight and metabolic factors were selected as defined by Cochrane Collaboration. Assessment of the effects of diets on predicted risk of atherosclerotic cardiovascular disease risk was added during the data collection phase.

Data Synthesis
1797 patients were included from 17 trials with $<$1 year follow up in 12. Compared with low fat diet, low carbohydrate was associated with significantly greater reduction in weight (Δ = -2.0 kg, 95\% CI: -3.1, -0.9) and significantly lower predicted risk of atherosclerotic cardiovascular disease events (p$<$0.03). Frequentist and Bayesian results were concordant. The probability of greater weight loss associated with low carbohydrate was $>$99\% while the reduction in predicted risk favoring low carbohydrate was $>$98\%.

Limitations
Lack of patient-level data and heterogeneity in dropout rates and outcomes reported.

Conclusions
This trial-level meta-analysis of randomized controlled trials comparing LoCHO diets with LoFAT diets in strictly adherent populations demonstrates that each diet was associated with significant weight loss and reduction in predicted risk of ASCVD events. However, LoCHO diet was associated with modest but significantly greater improvements in weight loss and predicted ASCVD risk in studies from 8 weeks to 24 months in duration. These results suggest that future evaluations of dietary guidelines should consider low carbohydrate diets as effective and safe intervention for weight management in the overweight and obese, although long-term effects require further investigation.},
  number = {10},
  journaltitle = {PLoS ONE},
  shortjournal = {PLoS One},
  urldate = {2016-03-23},
  date = {2015-10-20},
  author = {Sackner-Bernstein, Jonathan and Kanter, David and Kaul, Sanjay},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\A7T7TJUF\\Sackner-Bernstein et al. - 2015 - Dietary Intervention for Overweight and Obese Adul.pdf},
  eprinttype = {pmid},
  eprint = {26485706},
  pmcid = {PMC4618935}
}


@article{tiptonSiteSelectionExperiments2016,
  title = {Site {{Selection}} in {{Experiments}}: {{An Assessment}} of {{Site Recruitment}} and {{Generalizability}} in {{Two Scale}}-up {{Studies}}},
  volume = {9},
  issn = {1934-5747},
  url = {https://doi.org/10.1080/19345747.2015.1105895},
  doi = {10.1080/19345747.2015.1105895},
  shorttitle = {Site {{Selection}} in {{Experiments}}},
  abstract = {Recently, statisticians have begun developing methods to improve the generalizability of results from large-scale experiments in education. This work has included the development of methods for improved site selection when random sampling is infeasible, including the use of stratification and targeted recruitment strategies. This article provides the next step in this literature—a template for assessing generalizability after a study is completed. In this template, first records from the recruitment process are analyzed, comparing differences between those who agreed to be in the study and those who did not. Second, the final sample is compared to the original inference population and different possible subsets, with the goal of determining where the results best generalize (and where they do not). Throughout, these methods are situated in the post hoc analysis of results from two scale-up studies. The article ends with a discussion of the use of these methods more generally when reporting results from randomized trials.},
  issue = {sup1},
  journaltitle = {Journal of Research on Educational Effectiveness},
  urldate = {2018-12-05},
  date = {2016-10-03},
  pages = {209-228},
  keywords = {external validity,generalization,recruitment},
  author = {Tipton, Elizabeth and Fellers, Lauren and Caverly, Sarah and Vaden-Kiernan, Michael and Borman, Geoffrey and Sullivan, Kate and de Castilla, Veronica Ruiz},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\YCNS43HB\\Tipton et al. - 2016 - Site Selection in Experiments An Assessment of Si.pdf;C:\\Users\\Gleb\\Zotero\\storage\\9B5MP5FJ\\19345747.2015.html}
}


@online{SampleSelectionRandomized,
  title = {Sample {{Selection}} in {{Randomized Experiments}}: {{A New Method Using Propensity Score Stratified Sampling}}: {{Journal}} of {{Research}} on {{Educational Effectiveness}}: {{Vol}} 7, {{No}} 1},
  url = {https://www.tandfonline.com/doi/abs/10.1080/19345747.2013.831154},
  urldate = {2018-12-05},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\8R3NT5QA\\Sample Selection in Randomized Experiments A New .pdf;C:\\Users\\Gleb\\Zotero\\storage\\JPUZM4GF\\19345747.2013.html}
}


@article{tiptonHowGeneralizableYour2014,
  title = {How {{Generalizable Is Your Experiment}}? {{An Index}} for {{Comparing Experimental Samples}} and {{Populations}}},
  volume = {39},
  issn = {1076-9986},
  url = {https://www.jstor.org/stable/43966357},
  shorttitle = {How {{Generalizable Is Your Experiment}}?},
  abstract = {Although a large-scale experiment can provide an estimate of the average causal impact for a program, the sample of sites included in the experiment is often not drawn randomly from the inference population of interest. In this article, we provide a generalizability index that can be used to assess the degree of similarity between the sample of units in an experiment and one or more inference populations on a set of selected covariates. The index takes values between 0 and 1 and indicates both when a sample is like a miniature of the population and how well reweighting methods may perform when differences exist. Results of simulation studies are provided that develop rules of thumb for interpretation as well as an example.},
  number = {6},
  journaltitle = {Journal of Educational and Behavioral Statistics},
  urldate = {2018-12-05},
  date = {2014},
  pages = {478-501},
  author = {Tipton, Elizabeth},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\C929YILU\\Tipton - 2014 - How Generalizable Is Your Experiment An Index for.pdf}
}


@article{tiptonStratifiedSamplingUsing2013,
  langid = {english},
  title = {Stratified {{Sampling Using Cluster Analysis}}: {{A Sample Selection Strategy}} for {{Improved Generalizations From Experiments}}},
  volume = {37},
  issn = {0193-841X},
  url = {https://doi.org/10.1177/0193841X13516324},
  doi = {10.1177/0193841X13516324},
  shorttitle = {Stratified {{Sampling Using Cluster Analysis}}},
  abstract = {Background:An important question in the design of experiments is how to ensure that the findings from the experiment are generalizable to a larger population. This concern with generalizability is particularly important when treatment effects are heterogeneous and when selecting units into the experiment using random sampling is not possible?two conditions commonly met in large-scale educational experiments.Method:This article introduces a model-based balanced-sampling framework for improving generalizations, with a focus on developing methods that are robust to model misspecification. Additionally, the article provides a new method for sample selection within this framework: First units in an inference population are divided into relatively homogenous strata using cluster analysis, and then the sample is selected using distance rankings.Result:In order to demonstrate and evaluate the method, a reanalysis of a completed experiment is conducted. This example compares samples selected using the new method with the actual sample used in the experiment. Results indicate that even under high nonresponse, balance is better on most covariates and that fewer coverage errors result.Conclusion:The article concludes with a discussion of additional benefits and limitations of the method.},
  number = {2},
  journaltitle = {Evaluation Review},
  shortjournal = {Eval Rev},
  urldate = {2018-12-05},
  date = {2013-04-01},
  pages = {109-139},
  author = {Tipton, Elizabeth},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\UBJEYKFR\\Tipton - 2013 - Stratified Sampling Using Cluster Analysis A Samp.pdf}
}


@article{tiptonImprovingGeneralizationsExperiments2013,
  title = {Improving {{Generalizations From Experiments Using Propensity Score Subclassification}}: {{Assumptions}}, {{Properties}}, and {{Contexts}}},
  volume = {38},
  issn = {1076-9986},
  url = {https://www.jstor.org/stable/41999424},
  shorttitle = {Improving {{Generalizations From Experiments Using Propensity Score Subclassification}}},
  abstract = {As a result of the use of random assignment to treatment, randomized experiments typically have high internal validity. However, units are very rarely randomly selected from a well-defined population of interest into an experiment; this results in low external validity. Under nonrandom sampling, this means that the estimate of the sample average treatment effect calculated in the experiment can be a biased estimate of the population average treatment effect. This article explores the use of the propensity score subclassification estimator as a means for improving generalizations from experiments. It first lays out the assumptions necessary for generalizations, then investigates the amount of bias reduction and average variance inflation that is likely when compared to a conventional estimator. It concludes with a discussion of issues that arise when the population of interest is not well represented by the experiment, and an example.},
  number = {3},
  journaltitle = {Journal of Educational and Behavioral Statistics},
  urldate = {2018-12-05},
  date = {2013},
  pages = {239-266},
  author = {Tipton, Elizabeth},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\62FUAEDQ\\Tipton - 2013 - Improving Generalizations From Experiments Using P.pdf}
}


@article{sugarFindingNumberClusters2003,
  title = {Finding the {{Number}} of {{Clusters}} in a {{Dataset}}: {{An Information}}-{{Theoretic Approach}}},
  volume = {98},
  issn = {0162-1459},
  url = {https://www.jstor.org/stable/30045303},
  shorttitle = {Finding the {{Number}} of {{Clusters}} in a {{Dataset}}},
  abstract = {One of the most difficult problems in cluster analysis is identifying the number of groups in a dataset. Most previously suggested approaches to this problem are either somewhat ad hoc or require parametric assumptions and complicated calculations. In this article we develop a simple, yet powerful nonparametric method for choosing the number of clusters based on distortion, a quantity that measures the average distance, per dimension, between each observation and its closest cluster center. Our technique is computationally efficient and straightforward to implement. We demonstrate empirically its effectiveness, not only for choosing the number of clusters, but also for identifying underlying structure, on a wide range of simulated and real world datasets. In addition, we give a rigorous theoretical justification for the method based on information-theoretic ideas. Specifically, results from the subfield of electrical engineering known as rate distortion theory allow us to describe the behavior of the distortion in both the presence and absence of clustering. Finally, we note that these ideas potentially can be extended to a wide range of other statistical model selection problems.},
  number = {463},
  journaltitle = {Journal of the American Statistical Association},
  urldate = {2018-12-05},
  date = {2003},
  pages = {750-763},
  author = {Sugar, Catherine A. and James, Gareth M.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\JJ8WLUFK\\Sugar and James - 2003 - Finding the Number of Clusters in a Dataset An In.pdf}
}


@article{stuartMatchingMultipleControl2008,
  title = {Matching with {{Multiple Control Groups}} with {{Adjustment}} for {{Group Differences}}},
  volume = {33},
  issn = {1076-9986},
  url = {https://www.jstor.org/stable/20172119},
  abstract = {When estimating causal effects from observational data, it is desirable to approximate a randomized experiment as closely as possible. This goal can often be achieved by choosing a subsample from the original control group that matches the treatment group on the distribution of the observed covariates. However, sometimes the original control group cannot provide adequate matches for the treatment group. This article presents a method to obtain matches from multiple control groups. In addition to adjusting for differences in observed covariates between the groups, the method adjusts for a group effect that distinguishes between the control groups. This group effect captures the additional otherwise unobserved differences between the control groups, beyond that accounted for by the observed covariates. The method is illustrated and evaluated using data from an evaluation of a school drop-out prevention program that uses matches from both local and nonlocal control groups.},
  number = {3},
  journaltitle = {Journal of Educational and Behavioral Statistics},
  urldate = {2018-12-05},
  date = {2008},
  pages = {279-306},
  author = {Stuart, Elizabeth A. and Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\JYHD4DLE\\Stuart and Rubin - 2008 - Matching with Multiple Control Groups with Adjustm.pdf}
}


@inbook{stuartBestPracticesQuasi2008,
  location = {{2455 Teller Road,
Thousand Oaks
California
91320
United States of America}},
  title = {Best {{Practices}} in {{Quasi}}–{{Experimental Designs}}: {{Matching Methods}} for {{Causal Inference}}},
  isbn = {978-1-4129-4065-8 978-1-4129-9562-7},
  url = {http://methods.sagepub.com/book/best-practices-in-quantitative-methods/d14.xml},
  shorttitle = {Best {{Practices}} in {{Quasi}}–{{Experimental Designs}}},
  booktitle = {Best {{Practices}} in {{Quantitative Methods}}},
  publisher = {{SAGE Publications, Inc.}},
  urldate = {2018-12-05},
  date = {2008},
  pages = {155-176},
  author = {Stuart, Elizabeth A. and Rubin, Donald B.},
  bookauthor = {Osborne, Jason},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\58R725A4\\Stuart and Rubin - 2008 - Best Practices in Quasi–Experimental Designs Matc.pdf},
  doi = {10.4135/9781412995627.d14}
}


@online{CharacteristicsSchoolDistricts,
  title = {Characteristics of {{School Districts That Participate}} in {{Rigorous National Educational Evaluations}}: {{Journal}} of {{Research}} on {{Educational Effectiveness}}: {{Vol}} 10, {{No}} 1},
  url = {https://www.tandfonline.com/doi/abs/10.1080/19345747.2016.1205160},
  urldate = {2018-12-05},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\64B484BQ\\Characteristics of School Districts That Participa.pdf;C:\\Users\\Gleb\\Zotero\\storage\\HA69TEJK\\19345747.2016.html}
}


@article{stuartUsePropensityScores2011,
  langid = {english},
  title = {The Use of Propensity Scores to Assess the Generalizability of Results from Randomized Trials: {{Use}} of {{Propensity Scores}} to {{Assess Generalizability}}},
  volume = {174},
  issn = {09641998},
  url = {http://doi.wiley.com/10.1111/j.1467-985X.2010.00673.x},
  doi = {10.1111/j.1467-985X.2010.00673.x},
  shorttitle = {The Use of Propensity Scores to Assess the Generalizability of Results from Randomized Trials},
  number = {2},
  journaltitle = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  urldate = {2018-12-05},
  date = {2011-04},
  pages = {369-386},
  author = {Stuart, Elizabeth A. and Cole, Stephen R. and Bradshaw, Catherine P. and Leaf, Philip J.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\Z2VSWX4P\\Stuart et al. - 2011 - The use of propensity scores to assess the general.pdf}
}


@article{stuartMatchingMethodsCausal2010,
  title = {Matching {{Methods}} for {{Causal Inference}}: {{A Review}} and a {{Look Forward}}},
  volume = {25},
  issn = {0883-4237},
  url = {https://www.jstor.org/stable/41058994},
  shorttitle = {Matching {{Methods}} for {{Causal Inference}}},
  abstract = {When estimating causal effects using observational data, it is desirable to replicate a randomized experiment as closely as possible by obtaining treated and control groups with similar covariate distributions. This goal can often be achieved by choosing well-matched samples of the original treated and control groups, thereby reducing bias due to the covariates. Since the 1970s, work on matching methods has examined how to best choose treated and control subjects for comparison. Matching methods are gaining popularity in fields such as economics, epidemiology, medicine and political science. However, until now the literature and related advice has been scattered across disciplines. Researchers who are interested in using matching methods—or developing methods related to matching—do not have a single place to turn to learn about past and current research. This paper provides a structure for thinking about matching methods and guidance on their use, coalescing the existing research (both old and new) and providing a summary of where the literature on matching methods is now and where it should be headed.},
  number = {1},
  journaltitle = {Statistical Science},
  urldate = {2018-12-05},
  date = {2010},
  pages = {1-21},
  author = {Stuart, Elizabeth A.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\HPWYHXC5\\Stuart - 2010 - Matching Methods for Causal Inference A Review an.pdf}
}


@article{steinleyKmeansClusteringHalfcentury2006,
  langid = {english},
  title = {K-Means Clustering: {{A}} Half-Century Synthesis},
  volume = {59},
  issn = {2044-8317},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1348/000711005X48266},
  doi = {10.1348/000711005X48266},
  shorttitle = {K-Means Clustering},
  abstract = {This paper synthesizes the results, methodology, and research conducted concerning the K-means clustering method over the last fifty years. The K-means method is first introduced, various formulations of the minimum variance loss function and alternative loss functions within the same class are outlined, and different methods of choosing the number of clusters and initialization, variable preprocessing, and data reduction schemes are discussed. Theoretic statistical results are provided and various extensions of K-means using different metrics or modifications of the original algorithm are given, leading to a unifying treatment of K-means and some of its extensions. Finally, several future studies are outlined that could enhance the understanding of numerous subtleties affecting the performance of the K-means method.},
  number = {1},
  journaltitle = {British Journal of Mathematical and Statistical Psychology},
  urldate = {2018-12-05},
  date = {2006-05-01},
  pages = {1-34},
  author = {Steinley, Douglas},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\LSAJD8WP\\Steinley - 2006 - K-means clustering A half-century synthesis.pdf;C:\\Users\\Gleb\\Zotero\\storage\\CVTEN9SM\\000711005X48266.html}
}


@article{shadishCampbellRubinPrimer2010,
  langid = {english},
  title = {Campbell and {{Rubin}}: {{A}} Primer and Comparison of Their Approaches to Causal Inference in Field Settings.},
  volume = {15},
  issn = {1939-1463, 1082-989X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0015916},
  doi = {10.1037/a0015916},
  shorttitle = {Campbell and {{Rubin}}},
  number = {1},
  journaltitle = {Psychological Methods},
  urldate = {2018-12-05},
  date = {2010},
  pages = {3-17},
  author = {Shadish, William R.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\4YX7GQ47\\Shadish - 2010 - Campbell and Rubin A primer and comparison of the.pdf}
}


@article{schaferAverageCausalEffects2008,
  langid = {english},
  title = {Average Causal Effects from Nonrandomized Studies: {{A}} Practical Guide and Simulated Example.},
  volume = {13},
  issn = {1939-1463, 1082-989X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0014268},
  doi = {10.1037/a0014268},
  shorttitle = {Average Causal Effects from Nonrandomized Studies},
  abstract = {In a well-designed experiment, random assignment of participants to treatments makes causal inference straightforward. However, if participants are not randomized (as in observational study, quasi-experiment, or nonequivalent control-group designs), group comparisons may be biased by confounders that inﬂuence both the outcome and the alleged cause. Traditional analysis of covariance, which includes confounders as predictors in a regression model, often fails to eliminate this bias. In this article, the authors review Rubin’s deﬁnition of an average causal effect (ACE) as the average difference between potential outcomes under different treatments. The authors distinguish an ACE and a regression coefﬁcient. The authors review 9 strategies for estimating ACEs on the basis of regression, propensity scores, and doubly robust methods, providing formulas for standard errors not given elsewhere. To illustrate the methods, the authors simulate an observational study to assess the effects of dieting on emotional distress. Drawing repeated samples from a simulated population of adolescent girls, the authors assess each method in terms of bias, efﬁciency, and interval coverage. Throughout the article, the authors offer insights and practical guidance for researchers who attempt causal inference with observational data.},
  number = {4},
  journaltitle = {Psychological Methods},
  urldate = {2018-12-05},
  date = {2008},
  pages = {279-313},
  author = {Schafer, Joseph L. and Kang, Joseph},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\8JQHXH3M\\Schafer and Kang - 2008 - Average causal effects from nonrandomized studies.pdf}
}


@article{schaferAverageCausalEffects2008a,
  langid = {english},
  title = {Average Causal Effects from Nonrandomized Studies: {{A}} Practical Guide and Simulated Example.},
  volume = {13},
  issn = {1939-1463, 1082-989X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0014268},
  doi = {10.1037/a0014268},
  shorttitle = {Average Causal Effects from Nonrandomized Studies},
  number = {4},
  journaltitle = {Psychological Methods},
  urldate = {2018-12-05},
  date = {2008},
  pages = {279-313},
  author = {Schafer, Joseph L. and Kang, Joseph}
}


@collection{salkindEncyclopediaResearchDesign2010,
  location = {{Thousand Oaks, Calif}},
  title = {Encyclopedia of Research Design},
  isbn = {978-1-4129-6127-1},
  abstract = {"Comprising more than 500 entries, the Encyclopedia of Research Design explains how to make decisions about research design, undertake research projects in an ethicalmanner, interpret and draw valid inferences from data, andevaluate experiment design strategies and results. Two additional features carry this encyclopedia far above other works in the field: bibliographic entries devoted tosignificant articles in the history of research design andreviews of contemporary tools, such as software and statistical procedures, used to analyze results. It coversthe spectrum of research design strategies, from material presented in introductory classes to topics necessary in graduate research; it addresses cross- and multidisciplinary research needs, with many examples drawnfrom the social and behavioral sciences, neurosciences, and biomedical and life sciences; it provides summaries ofadvantages and disadvantages of often-used strategies; andit uses hundreds of sample tables, figures, and equations based on real-life cases."--Publisher's description},
  pagetotal = {3},
  publisher = {{SAGE Publications}},
  date = {2010},
  keywords = {Encyclopedias,Research Methodology,Social sciences,Statistical methods},
  editor = {Salkind, Neil J.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\4CDG2QFL\\Salkind - 2010 - Encyclopedia of research design - Rand Sampling.pdf;C:\\Users\\Gleb\\Zotero\\storage\\Q2NU83WQ\\Salkind - 2010 - Encyclopedia of research design - Prob Sampling.pdf},
  note = {OCLC: 436031218}
}


@article{rubinObjectiveCausalInference2008,
  title = {For {{Objective Causal Inference}}, {{Design Trumps Analysis}}},
  volume = {2},
  issn = {1932-6157},
  url = {https://www.jstor.org/stable/30245110},
  abstract = {[For obtaining causal inferences that are objective, and therefore have the best chance of revealing scientific truths, carefully designed and executed randomized experiments are generally considered to be the gold standard. Observational studies, in contrast, are generally fraught with problems that compromise any claim for objectivity of the resulting causal inferences. The thesis here is that observational studies have to be carefully designed to approximate randomized experiments, in particular, without examining any final outcome data. Often a candidate data set will have to be rejected as inadequate because of lack of data on key covariates, or because of lack of overlap in the distributions of key covariates between treatment and control groups, often revealed by careful propensity score analyses. Sometimes the template for the approximating randomized experiment will have to be altered, and the use of principal stratification can be helpful in doing this. These issues are discussed and illustrated using the framework of potential outcomes to define causal effects, which greatly clarifies critical issues.]},
  number = {3},
  journaltitle = {The Annals of Applied Statistics},
  urldate = {2018-12-05},
  date = {2008},
  pages = {808-840},
  author = {Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\CEQBAI46\\Rubin - 2008 - For Objective Causal Inference, Design Trumps Anal.pdf}
}


@article{rubinTeachingStatisticalInference2004,
  title = {Teaching {{Statistical Inference}} for {{Causal Effects}} in {{Experiments}} and {{Observational Studies}}},
  volume = {29},
  issn = {1076-9986},
  url = {https://www.jstor.org/stable/3701358},
  abstract = {Inference for causal effects is a critical activity in many branches of science and public policy. The field of statistics is the one field most suited to address such problems, whether from designed experiments or observational studies. Consequently, it is arguably essential that departments of statistics teach courses in causal inference to both graduate and undergraduate students. This article discusses an outline of such courses based on repeated experience over more than a decade.},
  number = {3},
  journaltitle = {Journal of Educational and Behavioral Statistics},
  urldate = {2018-12-05},
  date = {2004},
  pages = {343-367},
  author = {Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\CF6CXP32\\Rubin - 2004 - Teaching Statistical Inference for Causal Effects .pdf}
}


@article{rubinComment1986,
  title = {Comment},
  volume = {81},
  issn = {0162-1459},
  url = {https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1986.10478355},
  doi = {10.1080/01621459.1986.10478355},
  number = {396},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  urldate = {2018-12-05},
  date = {1986-12-01},
  pages = {961-962},
  author = {Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\34NX5PQU\\Rubin - 1986 - Comment.pdf;C:\\Users\\Gleb\\Zotero\\storage\\LWJRP9MC\\01621459.1986.html}
}


@article{rubinRandomizationAnalysisExperimental1980,
  title = {Randomization {{Analysis}} of {{Experimental Data}}: {{The Fisher Randomization Test Comment}}},
  volume = {75},
  issn = {0162-1459},
  url = {https://www.jstor.org/stable/2287653},
  doi = {10.2307/2287653},
  shorttitle = {Randomization {{Analysis}} of {{Experimental Data}}},
  number = {371},
  journaltitle = {Journal of the American Statistical Association},
  urldate = {2018-12-05},
  date = {1980},
  pages = {591-593},
  author = {Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\7M9QM3DE\\Rubin - 1980 - Randomization Analysis of Experimental Data The F.pdf}
}


@article{rubinAssignmentTreatmentGroup1977,
  langid = {english},
  title = {Assignment to {{Treatment Group}} on the {{Basis}} of a {{Covariate}}},
  volume = {2},
  issn = {0362-9791},
  url = {http://journals.sagepub.com/doi/10.3102/10769986002001001},
  doi = {10.3102/10769986002001001},
  number = {1},
  journaltitle = {Journal of Educational Statistics},
  urldate = {2018-12-05},
  date = {1977-03},
  pages = {1-26},
  author = {Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\NXAX7YFU\\Rubin - 1977 - Assignment to Treatment Group on the Basis of a Co.pdf}
}


@article{rubinInferenceMissingData1976,
  title = {Inference and {{Missing Data}}},
  volume = {63},
  issn = {0006-3444},
  url = {https://www.jstor.org/stable/2335739},
  doi = {10.2307/2335739},
  abstract = {[When making sampling distribution inferences about the parameter of the data, θ, it is appropriate to ignore the process that causes missing data if the missing data are `missing at random' and the observed data are `observed at random', but these inferences are generally conditional on the observed pattern of missing data. When making direct-likelihood or Bayesian inferences about θ, it is appropriate to ignore the process that causes missing data if the missing data are missing at random and the parameter of the missing data process is `distinct' from θ. These conditions are the weakest general conditions under which ignoring the process that causes missing data always leads to correct inferences.]},
  number = {3},
  journaltitle = {Biometrika},
  urldate = {2018-12-05},
  date = {1976},
  pages = {581-592},
  author = {Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\KTEV8DBW\\Rubin - 1976 - Inference and Missing Data.pdf}
}


@article{rubinEstimatingCausalEffects1974,
  langid = {english},
  title = {Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.},
  volume = {66},
  issn = {0022-0663},
  url = {http://content.apa.org/journals/edu/66/5/688},
  doi = {10.1037/h0037350},
  number = {5},
  journaltitle = {Journal of Educational Psychology},
  urldate = {2018-12-05},
  date = {1974},
  pages = {688-701},
  author = {Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\2YFUUHMV\\Rubin - 1974 - Estimating causal effects of treatments in randomi.pdf}
}


@article{rubinCharacterizingEstimationParameters1974,
  title = {Characterizing the {{Estimation}} of {{Parameters}} in {{Incomplete}}-{{Data Problems}}},
  volume = {69},
  issn = {0162-1459},
  url = {https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1974.10482976},
  doi = {10.1080/01621459.1974.10482976},
  abstract = {A framework is given for organizing and understanding the problems of estimating the parameters of a multivariate data set which contains blocks of missing observations. The basic technique is to decompose the original estimation problem into smaller estimation problems by factoring the likelihood of the observed data into a product of likelihoods. The result is summarized in a “factorization table,” which identifies the “complete-data” factors whose parameters may be estimated using standard, well-understood complete-data techniques, and the “incomplete-data” factors whose parameters must be estimated using special missing-data methods.},
  number = {346},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  urldate = {2018-12-05},
  date = {1974-06-01},
  pages = {467-474},
  author = {Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\7AKEM44Y\\Rubin - 1974 - Characterizing the Estimation of Parameters in Inc.pdf;C:\\Users\\Gleb\\Zotero\\storage\\AG3TMP9H\\01621459.1974.html}
}


@article{rubinUseMatchedSampling1973,
  title = {The {{Use}} of {{Matched Sampling}} and {{Regression Adjustment}} to {{Remove Bias}} in {{Observational Studies}}},
  volume = {29},
  issn = {0006-341X},
  url = {https://www.jstor.org/stable/2529685},
  doi = {10.2307/2529685},
  abstract = {[The ability of matched sampling and linear regression adjustment to reduce the bias of an estimate of the treatment effect in two sample observational studies is investigated for a simple matching method and five simple estimates. Monte Carlo results are given for moderately linear exponential response surfaces and analytic results are presented for quadratic response surfaces. The conclusions are (1) in general both matched sampling and regression adjustment can be expected to reduce bias, (2) in some cases when the variance of the matching variable differs in the two populations both matching and regression adjustment can increase bias, (3) when the variance of the matching variable is the same in the two populations and the distributions of the matching variable are symmetric the usual covariance adjusted estimate based on random samples is almost unbiased, and (4) the combination of regression adjustment in matched samples generally produces the least biased estimate.]},
  number = {1},
  journaltitle = {Biometrics},
  urldate = {2018-12-05},
  date = {1973},
  pages = {185-203},
  author = {Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\C65UQM6J\\Rubin - 1973 - The Use of Matched Sampling and Regression Adjustm.pdf}
}


@article{rosenbaumConstructingControlGroup1985,
  title = {Constructing a {{Control Group Using Multivariate Matched Sampling Methods That Incorporate}} the {{Propensity Score}}},
  volume = {39},
  issn = {0003-1305},
  url = {https://www.jstor.org/stable/2683903},
  doi = {10.2307/2683903},
  abstract = {[Matched sampling is a method for selecting units from a large reservoir of potential controls to produce a control group of modest size that is similar to a treated group with respect to the distribution of observed covariates. We illustrate the use of multivariate matching methods in an observational study of the effects of prenatal exposure to barbiturates on subsequent psychological development. A key idea is the use of the propensity score as a distinct matching variable.]},
  number = {1},
  journaltitle = {The American Statistician},
  urldate = {2018-12-05},
  date = {1985},
  pages = {33-38},
  author = {Rosenbaum, Paul R. and Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\FIE44DIJ\\Rosenbaum and Rubin - 1985 - Constructing a Control Group Using Multivariate Ma.pdf}
}


@article{rosenbaumReducingBiasObservational1984,
  title = {Reducing {{Bias}} in {{Observational Studies Using Subclassification}} on the {{Propensity Score}}},
  volume = {79},
  issn = {0162-1459},
  url = {https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1984.10478078},
  doi = {10.1080/01621459.1984.10478078},
  abstract = {The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Previous theoretical arguments have shown that subclassification on the propensity score will balance all observed covariates. Subclassification on an estimated propensity score is illustrated, using observational data on treatments for coronary artery disease. Five subclasses defined by the estimated propensity score are constructed that balance 74 covariates, and thereby provide estimates of treatment effects using direct adjustment. These subclasses are applied within sub-populations, and model-based adjustments are then used to provide estimates of treatment effects within these sub-populations. Two appendixes address theoretical issues related to the application: the effectiveness of subclassification on the propensity score in removing bias, and balancing properties of propensity scores with incomplete data.},
  number = {387},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  urldate = {2018-12-05},
  date = {1984-09-01},
  pages = {516-524},
  author = {Rosenbaum, Paul R. and Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\AXXSGFSG\\Rosenbaum and Rubin - 1984 - Reducing Bias in Observational Studies Using Subcl.pdf;C:\\Users\\Gleb\\Zotero\\storage\\U3VA62MU\\01621459.1984.html}
}


@article{rosenbaumCentralRolePropensity1983,
  title = {The {{Central Role}} of the {{Propensity Score}} in {{Observational Studies}} for {{Causal Effects}}},
  volume = {70},
  issn = {0006-3444},
  url = {https://www.jstor.org/stable/2335942},
  doi = {10.2307/2335942},
  abstract = {[The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a two-dimensional plot.]},
  number = {1},
  journaltitle = {Biometrika},
  urldate = {2018-12-05},
  date = {1983},
  pages = {41-55},
  author = {Rosenbaum, Paul R. and Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\WNGDU5IW\\Rosenbaum and Rubin - 1983 - The Central Role of the Propensity Score in Observ.pdf}
}


@inproceedings{pearlTransportabilityCausalStatistical2011,
  title = {Transportability of {{Causal}} and {{Statistical Relations}}: {{A Formal Approach}}},
  doi = {10.1109/ICDMW.2011.169},
  shorttitle = {Transportability of {{Causal}} and {{Statistical Relations}}},
  abstract = {We address the problem of transferring information learned from experiments to a different environment, in which only passive observations can be collected. We introduce a formal representation called "selection diagrams” for expressing knowledge about differences and commonalities between environments and, using this representation, we derive procedures for deciding whether effects in the target environment can be inferred from experiments conducted elsewhere. When the answer is affirmative, the procedures identify the set of experiments and observations that need be conducted to license the transport. We further discuss how transportability analysis can guide the transfer of knowledge in non-experimental learning to minimize re-measurement cost and improve prediction power.},
  eventtitle = {2011 {{IEEE}} 11th {{International Conference}} on {{Data Mining Workshops}}},
  booktitle = {2011 {{IEEE}} 11th {{International Conference}} on {{Data Mining Workshops}}},
  date = {2011-12},
  pages = {540-547},
  keywords = {Calculus,causal relation transportability,causal relations,Cities and towns,Diseases,experiments,formal representation,formal specification,knowledge transfer,learning (artificial intelligence),Licenses,Machine learning,nonexperimental learning,passive observations,Probability distribution,selection diagrams,statistical relation transportability,Training,transportability,transportability analysis},
  author = {Pearl, J. and Bareinboim, E.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\XSSQ82GU\\Pearl and Bareinboim - 2011 - Transportability of Causal and Statistical Relatio.pdf;C:\\Users\\Gleb\\Zotero\\storage\\7PEMCEF8\\6137426.html}
}


@online{TransportabilityCausalStatistical,
  title = {Transportability of {{Causal}} and {{Statistical Relations}}: {{A Formal Approach}} - {{IEEE Conference Publication}}},
  url = {https://ieeexplore.ieee.org/document/6137426},
  urldate = {2018-12-05},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\K9YDENUP\\6137426.html}
}


@article{omuircheartaighGeneralizingUnrepresentativeExperiments2014,
  langid = {english},
  title = {Generalizing from Unrepresentative Experiments: A Stratified Propensity Score Approach},
  volume = {63},
  issn = {00359254},
  url = {http://doi.wiley.com/10.1111/rssc.12037},
  doi = {10.1111/rssc.12037},
  shorttitle = {Generalizing from Unrepresentative Experiments},
  number = {2},
  journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  urldate = {2018-12-05},
  date = {2014-02},
  pages = {195-210},
  author = {O'Muircheartaigh, Colm and Hedges, Larry V.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\NLQC3ENV\\O'Muircheartaigh and Hedges - 2014 - Generalizing from unrepresentative experiments a .pdf}
}


@article{milliganExaminationProceduresDetermining1985,
  langid = {english},
  title = {An Examination of Procedures for Determining the Number of Clusters in a Data Set},
  volume = {50},
  issn = {1860-0980},
  url = {https://doi.org/10.1007/BF02294245},
  doi = {10.1007/BF02294245},
  abstract = {A Monte Carlo evaluation of 30 procedures for determining the number of clusters was conducted on artificial data sets which contained either 2, 3, 4, or 5 distinct nonoverlapping clusters. To provide a variety of clustering solutions, the data sets were analyzed by four hierarchical clustering methods. External criterion measures indicated excellent recovery of the true cluster structure by the methods at the correct hierarchy level. Thus, the clustering present in the data was quite strong. The simulation results for the stopping rules revealed a wide range in their ability to determine the correct number of clusters in the data. Several procedures worked fairly well, whereas others performed rather poorly. Thus, the latter group of rules would appear to have little validity, particularly for data sets containing distinct clusters. Applied researchers are urged to select one or more of the better criteria. However, users are cautioned that the performance of some of the criteria may be data dependent.},
  number = {2},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  urldate = {2018-12-05},
  date = {1985-06-01},
  pages = {159-179},
  keywords = {classification,numerical taxonomy,stopping rules},
  author = {Milligan, Glenn W. and Cooper, Martha C.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\DSFHMND7\\Milligan and Cooper - 1985 - An examination of procedures for determining the n.pdf}
}


@article{kernAssessingMethodsGeneralizing2016,
  title = {Assessing {{Methods}} for {{Generalizing Experimental Impact Estimates}} to {{Target Populations}}},
  volume = {9},
  issn = {1934-5747},
  url = {https://doi.org/10.1080/19345747.2015.1060282},
  doi = {10.1080/19345747.2015.1060282},
  abstract = {Randomized experiments are considered the gold standard for causal inference because they can provide unbiased estimates of treatment effects for the experimental participants. However, researchers and policymakers are often interested in using a specific experiment to inform decisions about other target populations. In education research, increasing attention is being paid to the potential lack of generalizability of randomized experiments because the experimental participants may be unrepresentative of the target population of interest. This article examines whether generalization may be assisted by statistical methods that adjust for observed differences between the experimental participants and members of a target population. The methods examined include approaches that reweight the experimental data so that participants more closely resemble the target population and methods that utilize models of the outcome. Two simulation studies and one empirical analysis investigate and compare the methods’ performance. One simulation uses purely simulated data while the other utilizes data from an evaluation of a school-based dropout prevention program. Our simulations suggest that machine learning methods outperform regression-based methods when the required structural (ignorability) assumptions are satisfied. When these assumptions are violated, all of the methods examined perform poorly. Our empirical analysis uses data from a multisite experiment to assess how well results from a given site predict impacts in other sites. Using a variety of extrapolation methods, predicted effects for each site are compared to actual benchmarks. Flexible modeling approaches perform best, although linear regression is not far behind. Taken together, these results suggest that flexible modeling techniques can aid generalization while underscoring the fact that even state-of-the-art statistical techniques still rely on strong assumptions.},
  number = {1},
  journaltitle = {Journal of Research on Educational Effectiveness},
  urldate = {2018-12-05},
  date = {2016-01-02},
  pages = {103-127},
  keywords = {Bayesian Additive Regression Trees external validity generalizability propensity score weighting},
  author = {Kern, Holger L. and Stuart, Elizabeth A. and Hill, Jennifer and Green, Donald P.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\UXJ39Z7E\\Kern et al. - 2016 - Assessing Methods for Generalizing Experimental Im.pdf;C:\\Users\\Gleb\\Zotero\\storage\\GR2Q56U5\\19345747.2015.html},
  eprinttype = {pmid},
  eprint = {27668031}
}


@article{kangDemystifyingDoubleRobustness2007,
  title = {Demystifying {{Double Robustness}}: {{A Comparison}} of {{Alternative Strategies}} for {{Estimating}} a {{Population Mean}} from {{Incomplete Data}}},
  volume = {22},
  issn = {0883-4237},
  url = {https://www.jstor.org/stable/27645858},
  shorttitle = {Demystifying {{Double Robustness}}},
  abstract = {When outcomes are missing for reasons beyond an investigator's control, there are two different ways to adjust a parameter estimate for covariates that may be related both to the outcome and to missingness. One approach is to model the relationships between the covariates and the outcome and use those relationships to predict the missing values. Another is to model the probabilities of missingness given the covariates and incorporate them into a weighted or stratified estimate. Doubly robust (DR) procedures apply both types of model simultaneously and produce a consistent estimate of the parameter if either of the two models has been correctly specified. In this article, we show that DR estimates can be constructed in many ways. We compare the performance of various DR and non-DR estimates of a population mean in a simulated example where both models are incorrect but neither is grossly misspecified. Methods that use inverse-probabilities as weights, whether they are DR or not, are sensitive to misspecification of the propensity model when some estimated propensities are small. Many DR methods perform better than simple inverse-probability weighting. None of the DR methods we tried, however, improved upon the performance of simple regression-based prediction of the missing values. This study does not represent every missing-data problem that will arise in practice. But it does demonstrate that, in at least some settings, two wrong models are not better than one.},
  number = {4},
  journaltitle = {Statistical Science},
  urldate = {2018-12-05},
  date = {2007},
  pages = {523-539},
  author = {Kang, Joseph D. Y. and Schafer, Joseph L.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\4SUYWG8R\\Kang and Schafer - 2007 - Demystifying Double Robustness A Comparison of Al.pdf}
}


@article{hennigHowFindAppropriate2013,
  langid = {english},
  title = {How to Find an Appropriate Clustering for Mixed-Type Variables with Application to Socio-Economic Stratification: {{How}} to {{Find}} an {{Appropriate Clustering}}},
  volume = {62},
  issn = {00359254},
  url = {http://doi.wiley.com/10.1111/j.1467-9876.2012.01066.x},
  doi = {10.1111/j.1467-9876.2012.01066.x},
  shorttitle = {How to Find an Appropriate Clustering for Mixed-Type Variables with Application to Socio-Economic Stratification},
  number = {3},
  journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  urldate = {2018-12-05},
  date = {2013-05},
  pages = {309-369},
  author = {Hennig, Christian and Liao, Tim F.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\VRJ6M95F\\Hennig and Liao - 2013 - How to find an appropriate clustering for mixed-ty.pdf}
}


@article{imbensNonparametricEstimationAverage2004,
  title = {Nonparametric {{Estimation}} of {{Average Treatment Effects}} under {{Exogeneity}}: {{A Review}}},
  volume = {86},
  issn = {0034-6535},
  url = {https://www.jstor.org/stable/3211657},
  shorttitle = {Nonparametric {{Estimation}} of {{Average Treatment Effects}} under {{Exogeneity}}},
  abstract = {Recently there has been a surge in econometric work focusing on estimating average treatment effects under various sets of assumptions. One strand of this literature has developed methods for estimating average treatment effects for a binary treatment under assumptions variously described as exogeneity, unconfoundedness, or selection on observables. The implication of these assumptions is that systematic (for example, average or distributional) differences in outcomes between treated and control units with the same values for the covariates are attributable to the treatment. Recent analysis has considered estimation and inference for average treatment effects under weaker assumptions than typical of the earlier literature by avoiding distributional and functional-form assumptions. Various methods of semiparametric estimation have been proposed, including estimating the unknown regression functions, matching, methods using the propensity score such as weighting and blocking, and combinations of these approaches. In this paper I review the state of this literature and discuss some of its unanswered questions, focusing in particular on the practical implementation of these methods, the plausibility of this exogeneity assumption in economic applications, the relative performance of the various semiparametric estimators when the key assumptions (unconfoundedness and overlap) are satisfied, alternative estimands such as quantile treatment effects, and alternate methods such as Bayesian inference.},
  number = {1},
  journaltitle = {The Review of Economics and Statistics},
  urldate = {2018-12-05},
  date = {2004},
  pages = {4-29},
  author = {Imbens, Guido W.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\Z3GC3QQR\\Imbens - 2004 - Nonparametric Estimation of Average Treatment Effe.pdf}
}


@article{bruscoComparisonLatentClass2017,
  langid = {english},
  title = {A Comparison of Latent Class, {{K}}-Means, and {{K}}-Median Methods for Clustering Dichotomous Data.},
  volume = {22},
  issn = {1939-1463, 1082-989X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000095},
  doi = {10.1037/met0000095},
  number = {3},
  journaltitle = {Psychological Methods},
  urldate = {2018-12-05},
  date = {2017-09},
  pages = {563-580},
  author = {Brusco, Michael J. and Shireman, Emilie and Steinley, Douglas},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\DA5BK2BD\\Brusco et al. - 2017 - A comparison of latent class, K-means, and K-media.pdf}
}


@article{bellWhereSocialExperiments2016,
  langid = {english},
  title = {On the “{{Where}}” of {{Social Experiments}}: {{The Nature}} and {{Extent}} of the {{Generalizability Problem}}: {{On}} the “{{Where}}” of {{Social Experiments}}},
  volume = {2016},
  issn = {10976736},
  url = {http://doi.wiley.com/10.1002/ev.20212},
  doi = {10.1002/ev.20212},
  shorttitle = {On the “{{Where}}” of {{Social Experiments}}},
  number = {152},
  journaltitle = {New Directions for Evaluation},
  urldate = {2018-12-05},
  date = {2016-12},
  pages = {47-59},
  author = {Bell, Stephen H. and Stuart, Elizabeth A.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\DR6LDUWS\\Bell and Stuart - 2016 - On the “Where” of Social Experiments The Nature a.pdf}
}


@software{hennigFpcFlexibleProcedures2018,
  title = {Fpc: {{Flexible Procedures}} for {{Clustering}}},
  url = {https://CRAN.R-project.org/package=fpc},
  shorttitle = {Fpc},
  abstract = {Various methods for clustering and cluster validation. Fixed point clustering. Linear regression clustering. Clustering by merging Gaussian mixture components. Symmetric and asymmetric discriminant projections for visualisation of the separation of groupings. Cluster validation statistics for distance based clustering including corrected Rand index. Cluster-wise cluster stability assessment. Methods for estimation of the number of clusters: Calinski-Harabasz, Tibshirani and Walther's prediction strength, Fang and Wang's bootstrap stability. Gaussian/multinomial mixture fitting for mixed continuous/categorical variables. Variable-wise statistics for cluster interpretation. DBSCAN clustering. Interface functions for many clustering methods implemented in R, including estimating the number of clusters with kmeans, pam and clara. Modality diagnosis for Gaussian mixtures. For an overview see package?fpc.},
  version = {2.1-11.1},
  urldate = {2018-12-05},
  date = {2018-07-20},
  keywords = {Cluster,Multivariate},
  author = {Hennig, Christian},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\7PWFLTXW\\Hennig - 2018 - fpc Flexible Procedures for Clustering.pdf}
}


@collection{everittClusterAnalysis2011,
  location = {{Chichester, West Sussex, U.K}},
  title = {Cluster Analysis},
  edition = {5th ed},
  isbn = {978-0-470-74991-3 978-0-470-97780-4 978-0-470-97781-1 978-0-470-97844-3},
  pagetotal = {330},
  series = {Wiley series in probability and statistics},
  publisher = {{Wiley}},
  date = {2011},
  keywords = {Cluster analysis,MATHEMATICS / Probability & Statistics / Multivariate Analysis},
  editor = {Everitt, Brian},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\IL7EXUND\\Everitt - 2011 - Cluster analysis.pdf},
  note = {OCLC: 666867900}
}


@article{imaiMisunderstandingsExperimentalistsObservationalists2008,
  langid = {english},
  title = {Misunderstandings between Experimentalists and Observationalists about Causal Inference},
  volume = {171},
  issn = {1467-985X},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-985X.2007.00527.x},
  doi = {10.1111/j.1467-985X.2007.00527.x},
  abstract = {Summary. We attempt to clarify, and suggest how to avoid, several serious misunderstandings about and fallacies of causal inference. These issues concern some of the most fundamental advantages and disadvantages of each basic research design. Problems include improper use of hypothesis tests for covariate balance between the treated and control groups, and the consequences of using randomization, blocking before randomization and matching after assignment of treatment to achieve covariate balance. Applied researchers in a wide range of scientific disciplines seem to fall prey to one or more of these fallacies and as a result make suboptimal design or analysis choices. To clarify these points, we derive a new four-part decomposition of the key estimation errors in making causal inferences. We then show how this decomposition can help scholars from different experimental and observational research traditions to understand better each other's inferential problems and attempted solutions.},
  number = {2},
  journaltitle = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  urldate = {2018-12-04},
  date = {2008-04-01},
  pages = {481-502},
  keywords = {Average treatment effects,Blocking,Covariate balance,Matching,Observational studies,Randomized experiments},
  author = {Imai, Kosuke and King, Gary and Stuart, Elizabeth A.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\JJZ8M4RX\\Imai et al. - 2008 - Misunderstandings between experimentalists and obs.pdf;C:\\Users\\Gleb\\Zotero\\storage\\QTQPHUKF\\j.1467-985X.2007.00527.html}
}


@article{hollandCausalInferenceRetrospective1988,
  langid = {english},
  title = {Causal {{Inference}} in {{Retrospective Studies}}},
  volume = {12},
  issn = {0193-841X},
  url = {https://doi.org/10.1177/0193841X8801200301},
  doi = {10.1177/0193841X8801200301},
  abstract = {The problem of drawing causal inferences from retrospective case-control studies is considered. A model for causal inference in prospective studies is reviewed and then applied to retrospective studies. The limitations of case-control studies are formulated in terms of the level of causally relevant parameters that can be estimated in such studies. An example using data from a large retrospective study of coffee-drinking and myocardial infarctions is used to illustrate the ideas of the article.},
  number = {3},
  journaltitle = {Evaluation Review},
  shortjournal = {Eval Rev},
  urldate = {2018-12-04},
  date = {1988-06-01},
  pages = {203-231},
  author = {Holland, Paul W. and Rubin, Donald B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\WM8PHXM4\\Holland and Rubin - 1988 - Causal Inference in Retrospective Studies.pdf}
}


@article{hollandStatisticsCausalInference1986,
  title = {Statistics and {{Causal Inference}}},
  volume = {81},
  issn = {0162-1459},
  url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1986.10478354},
  doi = {10.1080/01621459.1986.10478354},
  abstract = {Problems involving causal inference have dogged at the heels of statistics since its earliest days. Correlation does not imply causation, and yet causal conclusions drawn from a carefully designed experiment are often valid. What can a statistical model say about causation? This question is addressed by using a particular model for causal inference (Holland and Rubin 1983; Rubin 1974) to critique the discussions of other writers on causation and causal inference. These include selected philosophers, medical researchers, statisticians, econometricians, and proponents of causal modeling.},
  number = {396},
  journaltitle = {Journal of the American Statistical Association},
  urldate = {2018-12-04},
  date = {1986-12-01},
  pages = {945-960},
  keywords = {Association,Causal effect,Causal model,Experiments,Granger causality,Hill's nine factors,Koch's postulates,Mill's methods,Path diagrams,Philosophy,Probabilistic causality},
  author = {Holland, Paul W.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\593W6K27\\01621459.1986.html}
}


@online{FindItUT,
  title = {Find It@{{UT}}},
  url = {http://te7fv6dm8k.search.serialssolutions.com/?ctx_ver=Z39.88-2004&ctx_enc=info%3Aofi%2Fenc%3AUTF-8&rfr_id=info%3Asid%2Fsummon.serialssolutions.com&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rft.genre=article&rft.atitle=STATISTICS+AND+CAUSAL+INFERENCE&rft.jtitle=JOURNAL+OF+THE+AMERICAN+STATISTICAL+ASSOCIATION&rft.au=HOLLAND%2C+PW&rft.date=1986-12-01&rft.pub=AMER+STATISTICAL+ASSOC&rft.issn=0162-1459&rft.eissn=1537-274X&rft.volume=81&rft.issue=396&rft.spage=945&rft.epage=960&rft.externalDBID=n%2Fa&rft.externalDocID=A1986F049000009&paramdict=en-US},
  urldate = {2018-12-04},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\QJE9ALBT\\te7fv6dm8k.search.serialssolutions.com.html}
}


@article{hoMatchingNonparametricPreprocessing2007,
  title = {Matching as {{Nonparametric Preprocessing}} for {{Reducing Model Dependence}} in {{Parametric Causal Inference}}},
  volume = {15},
  issn = {1047-1987},
  url = {https://www.jstor.org/stable/25791893},
  abstract = {Although published works rarely include causal estimates from more than a few model specifications, authors usually choose the presented estimates from numerous trial runs readers never see. Given the often large variation in estimates across choices of control variables, functional forms, and other modeling assumptions, how can researchers ensure that the few estimates presented are accurate or representative? How do readers know that publications are not merely demonstrations that it is possible to find a specification that fits the author's favorite hypothesis? And how do we evaluate or even define statistical properties like unbiasedness or mean squared error when no unique model or estimator even exists? Matching methods, which offer the promise of causal inference with fewer assumptions, constitute one possible way forward, but crucial results in this fast-growing methodological literature are often grossly misinterpreted. We explain how to avoid these misinterpretations and propose a unified approach that makes it possible for researchers to preprocess data with matching (such as with the easy-to-use software we offer) and then to apply the best parametric techniques they would have used anyway. This procedure makes parametric models produce more accurate and considerably less model-dependent causal inferences.},
  number = {3},
  journaltitle = {Political Analysis},
  urldate = {2018-12-04},
  date = {2007},
  pages = {199-236},
  author = {Ho, Daniel E. and Imai, Kosuke and King, Gary and Stuart, Elizabeth A.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\2JXL5C8K\\Ho et al. - 2007 - Matching as Nonparametric Preprocessing for Reduci.pdf}
}


@article{flayStandardsEvidenceCriteria2005,
  langid = {english},
  title = {Standards of {{Evidence}}: {{Criteria}} for {{Efficacy}}, {{Effectiveness}} and {{Dissemination}}},
  volume = {6},
  issn = {1573-6695},
  url = {https://doi.org/10.1007/s11121-005-5553-y},
  doi = {10.1007/s11121-005-5553-y},
  shorttitle = {Standards of {{Evidence}}},
  abstract = {Ever increasing demands for accountability, together with the proliferation of lists of evidence-based prevention programs and policies, led the Society for Prevention Research to charge a committee with establishing standards for identifying effective prevention programs and policies. Recognizing that interventions that are effective and ready for dissemination are a subset of effective programs and policies, and that effective programs and policies are a subset of efficacious interventions, SPR’s Standards Committee developed overlapping sets of standards. We designed these Standards to assist practitioners, policy makers, and administrators to determine which interventions are efficacious, which are effective, and which are ready for dissemination. Under these Standards, an efficacious intervention will have been tested in at least two rigorous trials that (1) involved defined samples from defined populations, (2) used psychometrically sound measures and data collection procedures; (3) analyzed their data with rigorous statistical approaches; (4) showed consistent positive effects (without serious iatrogenic effects); and (5) reported at least one significant long-term follow-up. An effective intervention under these Standards will not only meet all standards for efficacious interventions, but also will have (1) manuals, appropriate training, and technical support available to allow third parties to adopt and implement the intervention; (2) been evaluated under real-world conditions in studies that included sound measurement of the level of implementation and engagement of the target audience (in both the intervention and control conditions); (3) indicated the practical importance of intervention outcome effects; and (4) clearly demonstrated to whom intervention findings can be generalized. An intervention recognized as ready for broad dissemination under these Standards will not only meet all standards for efficacious and effective interventions, but will also provide (1) evidence of the ability to “go to scale”; (2) clear cost information; and (3) monitoring and evaluation tools so that adopting agencies can monitor or evaluate how well the intervention works in their settings. Finally, the Standards Committee identified possible standards desirable for current and future areas of prevention science as the field develops. If successful, these Standards will inform efforts in the field to find prevention programs and policies that are of proven efficacy, effectiveness, or readiness for adoption and will guide prevention scientists as they seek to discover, research, and bring to the field new prevention programs and policies.},
  number = {3},
  journaltitle = {Prevention Science},
  shortjournal = {Prev Sci},
  urldate = {2018-12-04},
  date = {2005-09-01},
  pages = {151-175},
  keywords = {dissemination,effectiveness,efficacy,standards},
  author = {Flay, Brian R. and Biglan, Anthony and Boruch, Robert F. and Castro, Felipe González and Gottfredson, Denise and Kellam, Sheppard and Mościcki, Eve K. and Schinke, Steven and Valentine, Jeffrey C. and Ji, Peter},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\F9SIN2H4\\Flay et al. - 2005 - Standards of Evidence Criteria for Efficacy, Effe.pdf}
}


@article{dehejiaCausalEffectsNonexperimental1999,
  title = {Causal {{Effects}} in {{Nonexperimental Studies}}: {{Reevaluating}} the {{Evaluation}} of {{Training Programs}}},
  volume = {94},
  issn = {0162-1459},
  url = {https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1999.10473858},
  doi = {10.1080/01621459.1999.10473858},
  shorttitle = {Causal {{Effects}} in {{Nonexperimental Studies}}},
  abstract = {This article uses propensity score methods to estimate the treatment impact of the National Supported Work (NSW) Demonstration, a labor training program, on postintervention earnings. We use data from Lalonde's evaluation of nonexperimental methods that combine the treated units from a randomized evaluation of the NSW with nonexperimental comparison units drawn from survey datasets. We apply propensity score methods to this composite dataset and demonstrate that, relative to the estimators that Lalonde evaluates, propensity score estimates of the treatment impact are much closer to the experimental benchmark estimate. Propensity score methods assume that the variables associated with assignment to treatment are observed (referred to as ignorable treatment assignment, or selection on observables). Even under this assumption, it is difficult to control for differences between the treatment and comparison groups when they are dissimilar and when there are many preintervention variables. The estimated propensity score (the probability of assignment to treatment, conditional on preintervention variables) summarizes the preintervention variables. This offers a diagnostic on the comparability of the treatment and comparison groups, because one has only to compare the estimated propensity score across the two groups. We discuss several methods (such as stratification and matching) that use the propensity score to estimate the treatment impact. When the range of estimated propensity scores of the treatment and comparison groups overlap, these methods can estimate the treatment impact for the treatment group. A sensitivity analysis shows that our estimates are not sensitive to the specification of the estimated propensity score, but are sensitive to the assumption of selection on observables. We conclude that when the treatment and comparison groups overlap, and when the variables determining assignment to treatment are observed, these methods provide a means to estimate the treatment impact. Even though propensity score methods are not always applicable, they offer a diagnostic on the quality of nonexperimental comparison groups in terms of observable preintervention variables.},
  number = {448},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  urldate = {2018-12-04},
  date = {1999-12-01},
  pages = {1053-1062},
  author = {Dehejia, Rajeev H. and Wahba, Sadek},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\CL5RGGIV\\Dehejia and Wahba - 1999 - Causal Effects in Nonexperimental Studies Reevalu.pdf;C:\\Users\\Gleb\\Zotero\\storage\\CX5BTJQR\\01621459.1999.html}
}


@article{dawidConditionalIndependenceStatistical1979,
  title = {Conditional {{Independence}} in {{Statistical Theory}}},
  volume = {41},
  issn = {0035-9246},
  url = {https://www.jstor.org/stable/2984718},
  abstract = {Some simple heuristic properties of conditional independence are shown to form a conceptual framework for much of the theory of statistical inference. This framework is illustrated by an examination of the role of conditional independence in several diverse areas of the field of statistics. Topics covered include sufficiency and ancillarity, parameter identification, causal inference, prediction sufficiency, data selection mechanisms, invariant statistical models and a subjectivist approach to model-building.},
  number = {1},
  journaltitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
  urldate = {2018-12-04},
  date = {1979},
  pages = {1-31},
  author = {Dawid, A. P.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\I7RRG4PI\\Dawid - 1979 - Conditional Independence in Statistical Theory.pdf}
}


@article{bealIntroductionPropensityScores2014,
  langid = {english},
  title = {An {{Introduction}} to {{Propensity Scores}}: {{What}}, {{When}}, and {{How}}},
  volume = {34},
  issn = {0272-4316},
  url = {https://doi.org/10.1177/0272431613503215},
  doi = {10.1177/0272431613503215},
  shorttitle = {An {{Introduction}} to {{Propensity Scores}}},
  abstract = {The use of propensity scores as a method to promote causality in studies that cannot use random assignment has increased dramatically since its original publication in 1983. While the utility of these approaches is important, the concepts underlying their use are complex. The purpose of this article is to provide a basic tutorial for conducting analyses using propensity scores and what researchers should be aware of in reading papers that choose propensity scores as a method, as well as in conducting their own research. In addition to the explanations given, examples are presented, based on actual studies, which illustrate the use of propensity scores for regression adjustment, stratification, and matching. The syntax, datasets, and output used for these examples are available on http://jea.sagepub.com/content/early/recent for readers to download and follow.},
  number = {1},
  journaltitle = {The Journal of Early Adolescence},
  shortjournal = {The Journal of Early Adolescence},
  urldate = {2018-12-04},
  date = {2014-01-01},
  pages = {66-92},
  author = {Beal, Sarah J. and Kupzyk, Kevin A.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\LND9XQY6\\Beal and Kupzyk - 2014 - An Introduction to Propensity Scores What, When, .pdf}
}


@article{austinIntroductionPropensityScore2011,
  title = {An {{Introduction}} to {{Propensity Score Methods}} for {{Reducing}} the {{Effects}} of {{Confounding}} in {{Observational Studies}}},
  volume = {46},
  issn = {0027-3171},
  url = {https://doi.org/10.1080/00273171.2011.568786},
  doi = {10.1080/00273171.2011.568786},
  abstract = {The propensity score is the probability of treatment assignment conditional on observed baseline characteristics. The propensity score allows one to design and analyze an observational (nonrandomized) study so that it mimics some of the particular characteristics of a randomized controlled trial. In particular, the propensity score is a balancing score: conditional on the propensity score, the distribution of observed baseline covariates will be similar between treated and untreated subjects. I describe 4 different propensity score methods: matching on the propensity score, stratification on the propensity score, inverse probability of treatment weighting using the propensity score, and covariate adjustment using the propensity score. I describe balance diagnostics for examining whether the propensity score model has been adequately specified. Furthermore, I discuss differences between regression-based methods and propensity score-based methods for the analysis of observational data. I describe different causal average treatment effects and their relationship with propensity score analyses.},
  number = {3},
  journaltitle = {Multivariate Behavioral Research},
  urldate = {2018-12-04},
  date = {2011-05-31},
  pages = {399-424},
  author = {Austin, Peter C.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\97NQ5MIP\\Austin - 2011 - An Introduction to Propensity Score Methods for Re.pdf;C:\\Users\\Gleb\\Zotero\\storage\\D7IYIVAE\\00273171.2011.html},
  eprinttype = {pmid},
  eprint = {21818162}
}


@thesis{tiptonMethodsGeneralizingExperiments2011,
  langid = {english},
  location = {{United States -- Illinois}},
  title = {Methods for {{Generalizing}} from {{Experiments}}},
  url = {https://search.proquest.com/docview/871588912/abstract/8DD90ED81FE54A8APQ/1},
  abstract = {This dissertation is a collection of three papers that address issues of generalization and external validity through a statistical lens.
Chapter 1 addresses the problem of non-random sample selection bias in randomized experiments. This paper extends the use of propensity score matching methods that are often used in observational studies to address the problem of sample selection bias in experiments. Using a potential outcomes framework, I delineate the assumptions required to use this method, propose a subclassification estimator, and develop benchmarks for the expected amounts of average bias reduction and average variance inflation. For a well-defined population, I also provide a method for choosing a sub-population such that the experimental estimate is less biased.
Chapter 2 addresses the problem of parameterizing heterogeneous treatment effects (HTE) in randomized experiments. In addition to the standardized mean difference, this paper proposes a standardized individual treatment effect variance and argues that both of these parameters are needed—either separately or as a ratio—to summarize how well a treatment works for a particular population. After introducing the definitions of the parameters, I develop estimators of these parameters and their large-sample variances. I provide a simulation study to investigate small sample bias and interval coverage probabilities under three different treatment and control distribution pairs.
Chapter 3 addresses the problem of robust variance estimation in meta-analysis when the effect sizes are functions of correlated binary variables. I report the results of a large simulation study which focuses on the risk difference, log risk ratio, and log odds ratio effect sizes. This simulation study examines the accuracy of 95\% confidence intervals constructed using a robust variance estimator when the number of studies in the meta-analysis is small. I report results for both estimation of the mean effect (intercept) and the estimation of a slope.},
  pagetotal = {123},
  institution = {{Northwestern University}},
  type = {Ph.D.},
  urldate = {2018-12-04},
  date = {2011},
  keywords = {Effect size,External validity,Generalization,Heterogeneous treatment effects,Pure sciences,Robust variance estimation},
  author = {Tipton, Laura Elizabeth},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\GWHFZRGB\\Tipton - 2011 - Methods for Generalizing from Experiments.pdf}
}


@thesis{fellersDevelopingApproachDetermine2017,
  langid = {english},
  location = {{United States -- New York}},
  title = {Developing an Approach to Determine Generalizability: {{A}} Review of Efficacy and Effectiveness Trials Funded by the {{Institute}} of {{Education Sciences}}},
  url = {https://search.proquest.com/docview/1865595768/abstract/40FD82F4A0C24535PQ/1},
  shorttitle = {Developing an Approach to Determine Generalizability},
  abstract = {Since its establishment the Institute of Education Sciences has been creating opportunities and driving standards to generate research in education that is high quality rigorous, and relevant. This dissertation is an analysis of current practices in Goal III and Goal IV studies, in order to (1) better understand of the types of schools that agree to take part in these studies, and (2) an assess how representative these schools are in comparison to important policy relevant populations. This dissertation focuses on a subset of studies that were funded from 2005-2014 by the Department of Education, IES, under the NCER grants-funding arm. Studies included were those whose interventions were aimed at elementary students across core curriculum and ELL program areas. Study schools were compared to two main populations, the U.S population of elementary schools and Title I elementary schools, as well as these populations on a state level. The B-index, proposed by Tipton (2014) was the main value of comparison used to assess the compositional similarity, or generalizability, of study schools to these identified inference populations. The findings show that across all studies included in this analysis, participating schools were representative of the U.S. population of schools, B-index = 0.9. Comparisons were also made between this collection of schools and the respective populations at the state level. Results showed that these schools were not representative of any individual states (no B-index values were greater than 0.90). Across all included studies, schools that agreed to participate were more often located in urban areas, had higher rates of FRL students, had more minority students enrolled, and had more total students, in both district and school, than those schools in the population of U.S. schools. It is clear that the movement of education research is to be relevant to a larger audience. Through this study it is clear that, across studies, we are achieving some representation in IES funded studies. However, the finer comparisons, study samples to individual state and individual studies to these populations, show limited similarity between study schools and populations of interest to policy makers using these study findings to make decisions about their schools.},
  pagetotal = {130},
  institution = {{Columbia University}},
  type = {Ph.D.},
  urldate = {2018-12-04},
  date = {2017},
  keywords = {External validity,Pure sciences,Education,Generalizability,Recruitment},
  author = {Fellers, Lauren},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\VH9IMSKE\\Fellers - 2017 - Developing an approach to determine generalizabili.pdf}
}


@article{tiptonReviewStatisticalMethods2018,
  langid = {english},
  title = {A {{Review}} of {{Statistical Methods}} for {{Generalizing From Evaluations}} of {{Educational Interventions}}},
  issn = {0013-189X},
  url = {https://doi.org/10.3102/0013189X18781522},
  doi = {10.3102/0013189X18781522},
  abstract = {School-based evaluations of interventions are increasingly common in education research. Ideally, the results of these evaluations are used to make evidence-based policy decisions for students. However, it is difficult to make generalizations from these evaluations because the types of schools included in the studies are typically not selected randomly from a target population. This paper provides an overview of statistical methods for improving generalizations from intervention research in education. These are presented as a series of steps aimed at improving research design—particularly recruitment—as well as methods for assessing and summarizing generalizability and estimating treatment impacts for clearly defined target populations.},
  journaltitle = {Educational Researcher},
  shortjournal = {Educational Researcher},
  urldate = {2018-09-18},
  date = {2018-06-21},
  pages = {0013189X18781522},
  author = {Tipton, Elizabeth and Olsen, Robert B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\388UDFZJ\\Tipton and Olsen - 2018 - A Review of Statistical Methods for Generalizing F.pdf}
}


@article{bruscoComparisonLatentClass2017a,
  langid = {english},
  title = {A Comparison of Latent Class, {{K}}-Means, and {{K}}-Median Methods for Clustering Dichotomous Data.},
  volume = {22},
  issn = {1939-1463, 1082-989X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000095},
  doi = {10.1037/met0000095},
  number = {3},
  journaltitle = {Psychological Methods},
  urldate = {2018-04-01},
  date = {2017-09},
  pages = {563-580},
  author = {Brusco, Michael J. and Shireman, Emilie and Steinley, Douglas},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\IIVCVI26\\Brusco et al. - 2017 - A comparison of latent class, K-means, and K-media.pdf}
}


@article{steinleyKmeansClusteringHalfcentury2006a,
  langid = {english},
  title = {K-Means Clustering: {{A}} Half-Century Synthesis},
  volume = {59},
  issn = {00071102},
  url = {http://search.proquest.com/docview/216465055/abstract/CFAEBD25064B4C1FPQ/1},
  shorttitle = {K-Means Clustering},
  journaltitle = {British Journal of Mathematical \& Statistical Psychology; Leicester},
  urldate = {2018-04-01},
  date = {2006-05},
  pages = {1-34},
  keywords = {Statistical methods,Cluster analysis,Mathematics,Psychology,Statistics},
  author = {Steinley, Douglas},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\8S8EKKR4\\Steinley - 2006 - K-means clustering A half-century synthesis.pdf}
}


@article{tomarkenStructuralEquationModeling2004,
  title = {Structural {{Equation Modeling}}: {{Strengths}}, {{Limitations}}, and {{Misconceptions}}},
  volume = {1},
  issn = {1548-5943},
  url = {http://www.annualreviews.org.ezproxy.lib.utexas.edu/doi/10.1146/annurev.clinpsy.1.102803.144239},
  doi = {10.1146/annurev.clinpsy.1.102803.144239},
  shorttitle = {Structural {{Equation Modeling}}},
  abstract = {Because structural equation modeling (SEM) has become a very popular data-analytic technique, it is important for clinical scientists to have a balanced perception of its strengths and limitations. We review several strengths of SEM, with a particular focus on recent innovations (e.g., latent growth modeling, multilevel SEM models, and approaches for dealing with missing data and with violations of normality assumptions) that underscore how SEM has become a broad data-analytic framework with flexible and unique capabilities. We also consider several limitations of SEM and some misconceptions that it tends to elicit. Major themes emphasized are the problem of omitted variables, the importance of lower-order model components, potential limitations of models judged to be well fitting, the inaccuracy of some commonly used rules of thumb, and the importance of study design. Throughout, we offer recommendations for the conduct of SEM analyses and the reporting of results.},
  number = {1},
  journaltitle = {Annual Review of Clinical Psychology},
  shortjournal = {Annu. Rev. Clin. Psychol.},
  urldate = {2016-06-24},
  date = {2004-11-12},
  pages = {31-65},
  author = {Tomarken, Andrew J. and Waller, Niels G.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\QUQ3VB73\\Tomarken and Waller - 2004 - Structural Equation Modeling Strengths, Limitatio.pdf;C:\\Users\\Gleb\\Zotero\\storage\\8JIWCNJB\\annurev.clinpsy.1.102803.html}
}


@article{muthenLatentVariableModeling1997,
  langid = {english},
  title = {Latent {{Variable Modeling}} of {{Longitudinal}} and {{Multilevel Data}}},
  volume = {27},
  issn = {1467-9531},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9531.271034/abstract},
  doi = {10.1111/1467-9531.271034},
  abstract = {An overview is given of modeling of longitudinal and multilevel data using a latent variable framework. Particular emphasis is placed on growth modeling. A latent variable model is presented for three-level data, where the modeling of the longitudinal part of the data imposes both a covariance and a mean structure. Examples are discussed where repeated observations are made on students sampled within classrooms and schools.},
  number = {1},
  journaltitle = {Sociological Methodology},
  urldate = {2016-06-24},
  date = {1997-01-01},
  pages = {453-480},
  author = {Muthén, Bengt},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\XMU6FWVF\\abstract.html}
}


@article{vandenbergReviewSynthesisMeasurement2000,
  langid = {english},
  title = {A {{Review}} and {{Synthesis}} of the {{Measurement Invariance Literature}}: {{Suggestions}}, {{Practices}}, and {{Recommendations}} for {{Organizational Research}}},
  volume = {3},
  issn = {1094-4281, 1552-7425},
  url = {http://orm.sagepub.com.ezproxy.lib.utexas.edu/content/3/1/4},
  doi = {10.1177/109442810031002},
  shorttitle = {A {{Review}} and {{Synthesis}} of the {{Measurement Invariance Literature}}},
  abstract = {The establishment of measurement invariance across groups is a logical prerequisite to conducting substantive cross-group comparisons (e.g., tests of group mean differences, invariance of structural parameter estimates), but measurement invariance is rarely tested in organizational research. In this article, the authors (a) elaborate the importance of conducting tests of measurement invariance across groups, (b) review recommended practices for conducting tests of measurement invariance, (c) review applications of measurement invariance tests in substantive applications, (d) discuss issues involved in tests of various aspects of measurement invariance, (e) present an empirical example of the analysis of longitudinal measurement invariance, and (f) propose an integrative paradigm for conducting sequences of measurement invariance tests.},
  number = {1},
  journaltitle = {Organizational Research Methods},
  shortjournal = {Organizational Research Methods},
  urldate = {2016-06-24},
  date = {2000-01-01},
  pages = {4-70},
  author = {Vandenberg, Robert J. and Lance, Charles E.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\K5CPHUH6\\Vandenberg and Lance - 2000 - A Review and Synthesis of the Measurement Invarian.pdf;C:\\Users\\Gleb\\Zotero\\storage\\33UACZPS\\4.html}
}


@article{cheungEvaluatingGoodnessofFitIndexes2002,
  title = {Evaluating {{Goodness}}-of-{{Fit Indexes}} for {{Testing Measurement Invariance}}},
  volume = {9},
  issn = {1070-5511},
  url = {http://dx.doi.org/10.1207/S15328007SEM0902_5},
  doi = {10.1207/S15328007SEM0902_5},
  abstract = {Measurement invariance is usually tested using Multigroup Confirmatory Factor Analysis, which examines the change in the goodness-of-fit index (GFI) when cross-group constraints are imposed on a measurement model. Although many studies have examined the properties of GFI as indicators of overall model fit for single-group data, there have been none to date that examine how GFIs change when between-group constraints are added to a measurement model. The lack of a consensus about what constitutes significant GFI differences places limits on measurement invariance testing. We examine 20 GFIs based on the minimum fit function. A simulation under the two-group situation was used to examine changes in the GFIs (ΔGFIs) when invariance constraints were added. Based on the results, we recommend using Δcomparative fit index, ΔGamma hat, and ΔMcDonald's Noncentrality Index to evaluate measurement invariance. These three ΔGFIs are independent of both model complexity and sample size, and are not correlated with the overall fit measures. We propose critical values of these ΔGFIs that indicate measurement invariance.},
  number = {2},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  urldate = {2016-06-24},
  date = {2002-04-01},
  pages = {233-255},
  author = {Cheung, Gordon W. and Rensvold, Roger B.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\JGWBMXPR\\Cheung and Rensvold - 2002 - Evaluating Goodness-of-Fit Indexes for Testing Mea.pdf;C:\\Users\\Gleb\\Zotero\\storage\\I9863C4H\\S15328007SEM0902_5.html}
}


@article{hedgesEstimationEffectSize1982,
  title = {Estimation of Effect Size from a Series of Independent Experiments},
  volume = {92},
  issn = {0033-2909},
  url = {http://ezproxy.lib.utexas.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=1983-00212-001&site=ehost-live},
  doi = {10.1037/0033-2909.92.2.490},
  abstract = {Extends statistical theory for procedures based on the Glass estimator of effect size for methods used in the quantitative synthesis of research. An unbiased estimator of effect size is given. A weighted estimator of effect size based on data from several experiments is defined and shown to be optimal (asymptotically efficient). An approximate (large-sample) test for homogeneity of effect size across experiments is also given. The results of an empirical sampling study show that the large-sample distributions of the weighted estimator and the homogeneity statistic are quite accurate when the experimental and control group sample sizes exceed 10 and the effect sizes are smaller than about 1.5. (12 ref) (PsycINFO Database Record (c) 2013 APA, all rights reserved)},
  number = {2},
  journaltitle = {Psychological Bulletin},
  shortjournal = {Psychological Bulletin},
  urldate = {2016-06-23},
  date = {1982-09},
  pages = {490-499},
  keywords = {Estimation,estimation of effect sizes for 2 or more independent studies,Experimentation,Statistical Significance},
  author = {Hedges, Larry V.}
}


@report{davisOccupationalPrestigeRatings1992,
  title = {Occupational {{Prestige Ratings}} from the 1989 {{General Social Survey}}: {{Version}} 1},
  url = {http://www.icpsr.umich.edu/ICPSR/studies/09593/version/1},
  shorttitle = {Occupational {{Prestige Ratings}} from the 1989 {{General Social Survey}}},
  urldate = {2016-06-23},
  date = {1992-01-10},
  author = {Davis, James A. and Smith, Tom W. and Hodge, Robert W. and Nakao, Keiko and Treas, Judith}
}


@book{allisonMissingData2002,
  location = {{Thousand Oaks, Calif}},
  title = {Missing Data},
  isbn = {978-0-7619-1672-7},
  pagetotal = {93},
  number = {no. 07-136},
  series = {Sage university papers. Quantitative applications in the social sciences},
  publisher = {{Sage Publications}},
  date = {2002},
  keywords = {Mathematical statistics,Missing observations (Statistics)},
  author = {Allison, Paul David}
}


@book{endersAppliedMissingData2010,
  location = {{New York}},
  title = {Applied {{Missing Data Analysis}}},
  isbn = {978-1-60623-641-3},
  publisher = {{Guilford Publications}},
  date = {2010},
  author = {Enders, Craig K.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\9FKBZG77\\FullRecord.html}
}


@book{hayesIntroductionMediationModeration2013,
  location = {{New York}},
  title = {Introduction to {{Mediation}}, {{Moderation}}, and {{Conditional Process Analysis}} : {{A Regression}}-{{Based Approach}}},
  isbn = {978-1-4625-1128-0},
  shorttitle = {Introduction to {{Mediation}}, {{Moderation}}, and {{Conditional Process Analysis}}},
  publisher = {{Guilford Publications}},
  date = {2013},
  author = {Hayes, Andrew F.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\5996CB6G\\FullRecord.html}
}


@online{EBLReaderIntroduction,
  title = {{{EBL Reader}} - {{Introduction}} to {{Mediation}}, {{Moderation}}, and {{Conditional Process Analysis}} : {{A Regression}}-{{Based Approach}}},
  url = {http://reader.eblib.com.ezproxy.lib.utexas.edu/(S(pqhddmrsg3g2w4no3kce4tvq))/Reader.aspx?p=1186800&o=429&u=DoxQVFjVEXM%3d&t=1466700091&h=7785E6943562B8083678F66B1F30603D196C8BDA&s=46316156&ut=1296&pg=1&r=img&c=-1&pat=n&cms=-1&sd=2#},
  urldate = {2016-06-23},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\7MWBP9HH\\Reader.html}
}


@article{ridgewayPropensityScoreAnalysis2015,
  title = {Propensity {{Score Analysis}} with {{Survey Weighted Data}}},
  volume = {3},
  issn = {2193-3677, 2193-3685},
  url = {http://www.degruyter.com/view/j/jci.2015.3.issue-2/jci-2014-0039/jci-2014-0039.xml},
  doi = {10.1515/jci-2014-0039},
  number = {2},
  journaltitle = {Journal of Causal Inference},
  urldate = {2016-05-17},
  date = {2015-01-01},
  author = {Ridgeway, Greg and Kovalchik, Stephanie Ann and Griffin, Beth Ann and Kabeto, Mohammed U.}
}


@article{harelInferencesMissingInformation2007,
  title = {Inferences on Missing Information under Multiple Imputation and Two-Stage Multiple Imputation},
  volume = {4},
  issn = {1572-3127},
  url = {http://www.sciencedirect.com/science/article/pii/S1572312706000153},
  doi = {10.1016/j.stamet.2006.03.002},
  abstract = {In the presence of missing values, researchers may be interested in the rates of missing information. The rates of missing information are (a) important for assessing how the missing information contributes to inferential uncertainty about, Q , the population quantity of interest, (b) are an important component in the decision of the number of imputations, and (c) can be used to test model uncertainty and model fitting. In this article I will derive the asymptotic distribution of the rates of missing information in two scenarios: the conventional multiple imputation (MI), and the two-stage MI. Numerically I will show that the proposed asymptotic distribution agrees with the simulated one. I will also suggest the number of imputations needed to obtain reliable missing information rate estimates for each method, based on the asymptotic distribution.},
  number = {1},
  journaltitle = {Statistical Methodology},
  shortjournal = {Statistical Methodology},
  urldate = {2016-05-16},
  date = {2007-01},
  pages = {75-89},
  keywords = {Missing data,Missing information,Multiple imputation},
  author = {Harel, Ofer},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\VAPB6B4H\\Harel - 2007 - Inferences on missing information under multiple i.pdf;C:\\Users\\Gleb\\Zotero\\storage\\ZXTIH2XA\\S1572312706000153.html}
}


@online{MiceMultivariateImputation,
  title = {Mice: {{Multivariate Imputation}} by {{Chained Equations}} in {{R}} | van {{Buuren}} | {{Journal}} of {{Statistical Software}}},
  url = {https://www.jstatsoft.org/article/view/v045i03},
  shorttitle = {Mice},
  urldate = {2016-05-16},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\H9CSBP9A\\2011 - von Buuren - MICE in R.pdf;C:\\Users\\Gleb\\Zotero\\storage\\IDAJSVQ7\\v045i03.html}
}


@article{maccallumApplicationsStructuralEquation2000,
  title = {Applications of {{Structural Equation Modeling}} in {{Psychological Research}}},
  volume = {51},
  url = {http://dx.doi.org/10.1146/annurev.psych.51.1.201},
  doi = {10.1146/annurev.psych.51.1.201},
  abstract = {This chapter presents a review of applications of structural equation modeling (SEM) published in psychological research journals in recent years. We focus first on the variety of research designs and substantive issues to which SEM can be applied productively. We then discuss a number of methodological problems and issues of concern that characterize some of this literature. Although it is clear that SEM is a powerful tool that is being used to great benefit in psychological research, it is also clear that the applied SEM literature is characterized by some chronic problems and that this literature can be considerably improved by greater attention to these issues.},
  number = {1},
  journaltitle = {Annual Review of Psychology},
  urldate = {2016-05-12},
  date = {2000},
  pages = {201-226},
  author = {MacCallum, Robert C. and Austin, James T.},
  eprinttype = {pmid},
  eprint = {10751970}
}


@article{westonBriefGuideStructural2006,
  langid = {english},
  title = {A {{Brief Guide}} to {{Structural Equation Modeling}}},
  volume = {34},
  issn = {0011-0000, 1552-3861},
  url = {http://tcp.sagepub.com.ezproxy.lib.utexas.edu/content/34/5/719},
  doi = {10.1177/0011000006286345},
  abstract = {To complement recent articles in this journal on structural equation modeling (SEM) practice and principles by Martens and by Quintana and Maxwell, respectively, the authors offer a consumer’s guide to SEM. Using an example derived from theory and research on vocational psychology, the authors outline six steps in SEM: model specification, identification, data preparation and screening, estimation, evaluation of fit, and modification. In addition, the authors summarize the debates surrounding some aspects of SEM (e.g., acceptable sample size, fit indices), with recommendations for application. They also discuss the need for considering and testing alternative models and present an example, with details on determining whether alternative models result in a significant improvement in fit to the observed data.},
  number = {5},
  journaltitle = {The Counseling Psychologist},
  shortjournal = {The Counseling Psychologist},
  urldate = {2016-05-12},
  date = {2006-01-09},
  pages = {719-751},
  author = {Weston, Rebecca and Gore, Paul A.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\WV99E5A7\\Weston and Gore - 2006 - A Brief Guide to Structural Equation Modeling.pdf;C:\\Users\\Gleb\\Zotero\\storage\\W97IDN7X\\719.html}
}


@online{ControlTypeErrors,
  title = {Control of {{Type I Errors}} with {{Multiple Tests}} of {{Constraints}} in {{Structural Equation Modeling}} - {{Multivariate Behavioral Research}} - {{Volume}} 32, {{Issue}} 1},
  url = {http://www.tandfonline.com.ezproxy.lib.utexas.edu/doi/abs/10.1207/s15327906mbr3201_2},
  urldate = {2016-05-12},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\XNWDX5WX\\s15327906mbr3201_2.html}
}


@article{greenControlTypeErrors1997,
  title = {Control of {{Type I Errors}} with {{Multiple Tests}} of {{Constraints}} in {{Structural Equation Modeling}}},
  volume = {32},
  issn = {0027-3171},
  url = {http://dx.doi.org/10.1207/s15327906mbr3201_2},
  doi = {10.1207/s15327906mbr3201_2},
  abstract = {Two contrasting views toward the evaluation of multiple tests of constraints and control of Type 1 errors in structural equation modeling are presented. (a) Exploring; data helps researchers make decisions about inclusion of relevant model parameters and control of Type 1 errors hinders this process. (b) Exploring data is not likely to yield meaningful models unless we can limit the process on the basis of methods and theory, and controlling Type I errors is a useful device: to force us to limit our searches. Also, in evaluating multiple tests of constraints for applications other than exploratory analyses, we should control for Type I errors as we do in testing multiple comparisons in analysis of variance. We argue for the second perspective and present examples to illustrate methods for controlling Type 1 errors when making model comparisons.},
  number = {1},
  journaltitle = {Multivariate Behavioral Research},
  urldate = {2016-05-12},
  date = {1997-01-01},
  pages = {39-51},
  author = {Green, Samuel B. and Babyak, Michael A.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\9TJCCZPS\\Green and Babyak - 1997 - Control of Type I Errors with Multiple Tests of Co.pdf;C:\\Users\\Gleb\\Zotero\\storage\\8FZ9IJXH\\s15327906mbr3201_2.html},
  eprinttype = {pmid},
  eprint = {26751105}
}


@article{greenMonteCarloInvestigation1998,
  title = {A {{Monte Carlo Investigation}} of {{Methods}} for {{Controlling Type I Errors}} with {{Specification Searches}} in {{Structural Equation Modeling}}},
  volume = {33},
  issn = {0027-3171},
  url = {http://dx.doi.org/10.1207/s15327906mbr3303_3},
  doi = {10.1207/s15327906mbr3303_3},
  abstract = {A standard strategy in structural equation modeling is to conduct multiple Lagrange multiplier (LM) tests after rejection of an initial model. Controlling for Type 1 error across these tests minimizes the likelihood of including unnecessary additional parameters in the model. Three methods for controlling Type I errors are evaluated using simulated data for factor analytic models: the standard approach which involves testing each parameter at the .05 level, a Bonferroni approach, and a simultaneous test procedure (STP). In the first part of the study, all samples were generated from a population in which all null hypotheses associated with the LM tests were correct. Three factors were manipu1, ted: factor weights, sample size, and number of parameters in the specification search. The standard and the STP approaches yielded overly liberal and overly conservative familywise error rates, respectively, while the Bonferroni approach yielded error rates closer to the nominal level. In the second part of the study, data were generated in which one or more null hypotheses associated with the LM test were incorrect, and the number of parameters in the search was manipulated. Again the Bonferroni method was the best approach in controlling familywise: error rate, particularly when the alpha level was adjusted for the number of parameters evaluated at each step.},
  number = {3},
  journaltitle = {Multivariate Behavioral Research},
  urldate = {2016-05-12},
  date = {1998-07-01},
  pages = {365-383},
  author = {Green, Samuel B. and Thompson, Marilyn S. and Babyak, Michael A.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\A29AE33T\\Green et al. - 1998 - A Monte Carlo Investigation of Methods for Control.pdf;C:\\Users\\Gleb\\Zotero\\storage\\8BSA4BE7\\s15327906mbr3303_3.html},
  eprinttype = {pmid},
  eprint = {26782719}
}


@article{brockwellComparisonStatisticalMethods2001,
  langid = {english},
  title = {A Comparison of Statistical Methods for Meta-Analysis},
  volume = {20},
  issn = {1097-0258},
  url = {http://onlinelibrary.wiley.com.ezproxy.lib.utexas.edu/doi/10.1002/sim.650/abstract},
  doi = {10.1002/sim.650},
  abstract = {Meta-analysis may be used to estimate an overall effect across a number of similar studies. A number of statistical techniques are currently used to combine individual study results. The simplest of these is based on a fixed effects model, which assumes the true effect is the same for all studies. A random effects model, however, allows the true effect to vary across studies, with the mean true effect the parameter of interest. We consider three methods currently used for estimation within the framework of a random effects model, and illustrate them by applying each method to a collection of six studies on the effect of aspirin after myocardial infarction. These methods are compared using estimated coverage probabilities of confidence intervals for the overall effect. The techniques considered all generally have coverages below the nominal level, and in particular it is shown that the commonly used DerSimonian and Laird method does not adequately reflect the error associated with parameter estimation, especially when the number of studies is small. Copyright © 2001 John Wiley \& Sons, Ltd.},
  number = {6},
  journaltitle = {Statistics in Medicine},
  shortjournal = {Statist. Med.},
  urldate = {2016-05-11},
  date = {2001-03-30},
  pages = {825-840},
  author = {Brockwell, Sarah E. and Gordon, Ian R.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\23XHAKWP\\Brockwell and Gordon - 2001 - A comparison of statistical methods for meta-analy.pdf;C:\\Users\\Gleb\\Zotero\\storage\\AVM89CK8\\abstract.html}
}


@article{kontopantelisPerformanceStatisticalMethods2012,
  langid = {english},
  title = {Performance of Statistical Methods for Meta-Analysis When True Study Effects Are Non-Normally Distributed: {{A}} Comparison between {{DerSimonian}}–{{Laird}} and Restricted Maximum Likelihood},
  volume = {21},
  issn = {0962-2802, 1477-0334},
  url = {http://smm.sagepub.com/content/21/6/657},
  doi = {10.1177/0962280211413451},
  shorttitle = {Performance of Statistical Methods for Meta-Analysis When True Study Effects Are Non-Normally Distributed},
  number = {6},
  journaltitle = {Statistical Methods in Medical Research},
  shortjournal = {Stat Methods Med Res},
  urldate = {2016-05-11},
  date = {2012-12-01},
  pages = {657-659},
  author = {Kontopantelis, Evangelos and Reeves, David},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\TI437XEA\\Kontopantelis and Reeves - 2012 - Performance of statistical methods for meta-analys.html},
  eprinttype = {pmid},
  eprint = {23171971}
}


@article{tanner-smithRobustVarianceEstimation2014,
  langid = {english},
  title = {Robust Variance Estimation with Dependent Effect Sizes: Practical Considerations Including a Software Tutorial in {{Stata}} and Spss},
  volume = {5},
  issn = {1759-2887},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/jrsm.1091/abstract},
  doi = {10.1002/jrsm.1091},
  shorttitle = {Robust Variance Estimation with Dependent Effect Sizes},
  abstract = {Methodologists have recently proposed robust variance estimation as one way to handle dependent effect sizes in meta-analysis. Software macros for robust variance estimation in meta-analysis are currently available for Stata (StataCorp LP, College Station, TX, USA) and spss (IBM, Armonk, NY, USA), yet there is little guidance for authors regarding the practical application and implementation of those macros. This paper provides a brief tutorial on the implementation of the Stata and spss macros and discusses practical issues meta-analysts should consider when estimating meta-regression models with robust variance estimates. Two example databases are used in the tutorial to illustrate the use of meta-analysis with robust variance estimates. Copyright © 2013 John Wiley \& Sons, Ltd.},
  number = {1},
  journaltitle = {Research Synthesis Methods},
  shortjournal = {Res. Syn. Meth.},
  urldate = {2016-04-25},
  date = {2014-03-01},
  pages = {13-30},
  keywords = {dependent effect sizes,robust variance estimation,software tutorial},
  author = {Tanner-Smith, Emily E. and Tipton, Elizabeth},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\HFDR54AS\\abstract.html}
}


@article{kontopantelisPerformanceStatisticalMethods2012a,
  langid = {english},
  title = {Performance of Statistical Methods for Meta-Analysis When True Study Effects Are Non-Normally Distributed: {{A}} Comparison between {{DerSimonian}}–{{Laird}} and Restricted Maximum Likelihood},
  volume = {21},
  issn = {0962-2802, 1477-0334},
  url = {http://smm.sagepub.com/content/21/6/657},
  doi = {10.1177/0962280211413451},
  shorttitle = {Performance of Statistical Methods for Meta-Analysis When True Study Effects Are Non-Normally Distributed},
  number = {6},
  journaltitle = {Statistical Methods in Medical Research},
  shortjournal = {Stat Methods Med Res},
  urldate = {2016-04-25},
  date = {2012-12-01},
  pages = {657-659},
  author = {Kontopantelis, Evangelos and Reeves, David},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\ZNARZRPG\\657.html},
  eprinttype = {pmid},
  eprint = {23171971}
}


@article{hedgesRobustVarianceEstimation2010,
  langid = {english},
  title = {Robust Variance Estimation in Meta-Regression with Dependent Effect Size Estimates},
  volume = {1},
  issn = {1759-2879},
  doi = {10.1002/jrsm.5},
  abstract = {Conventional meta-analytic techniques rely on the assumption that effect size estimates from different studies are independent and have sampling distributions with known conditional variances. The independence assumption is violated when studies produce several estimates based on the same individuals or there are clusters of studies that are not independent (such as those carried out by the same investigator or laboratory). This paper provides an estimator of the covariance matrix of meta-regression coefficients that are applicable when there are clusters of internally correlated estimates. It makes no assumptions about the specific form of the sampling distributions of the effect sizes, nor does it require knowledge of the covariance structure of the dependent estimates. Moreover, this paper demonstrates that the meta-regression coefficients are consistent and asymptotically normally distributed and that the robust variance estimator is valid even when the covariates are random. The theory is asymptotic in the number of studies, but simulations suggest that the theory may yield accurate results with as few as 20-40 studies. Copyright © 2010 John Wiley \& Sons, Ltd.},
  number = {1},
  journaltitle = {Research Synthesis Methods},
  shortjournal = {Res Synth Methods},
  date = {2010-01},
  pages = {39-65},
  keywords = {dependent effects,meta analysis,meta regression,robust standard errors},
  author = {Hedges, Larry V. and Tipton, Elizabeth and Johnson, Matthew C.},
  eprinttype = {pmid},
  eprint = {26056092}
}


@article{malloyComparisonMethodsFixed2011,
  langid = {english},
  title = {Comparison of Methods for Fixed Effect Meta-Regression of Standardized Differences of Means},
  volume = {5},
  issn = {1935-7524},
  url = {http://projecteuclid.org/euclid.ejs/1298644285},
  doi = {10.1214/11-EJS598},
  abstract = {Given a number of different studies estimating the same effect size, it is often desired to explain heterogeneity of outcomes using concomitant covariates. For very large sample sizes, effect size estimates are approximately normally distributed and a straightforward application of weighted least squares is appropriate. However in practice within study sample variances are often small to moderate, casting doubt on the normality assumption for effect sizes and results based on weighted least squares. One can alternatively variance stabilize the effect size estimates and adopt a generalized linear model. Both methods are compared on two examples when effect sizes are the standardized difference of means. Then simulation studies are conducted to compare the coverage and width of confidence intervals for the meta-regression coefficients. These simulations show that the coverage probability associated with weighted least squares can be well below the nominated level for small to moderate sample sizes. Further empirical investigations reveal a bias in estimation due to using estimated weights which were assumed to be known. For these models, the generalized linear model approach resulted in much improved coverage probabilities.},
  journaltitle = {Electronic Journal of Statistics},
  shortjournal = {Electron. J. Statist.},
  urldate = {2016-04-25},
  date = {2011},
  pages = {83-101},
  keywords = {generalized linear model,Weighted least squares},
  author = {Malloy, Michael J. and Prendergast, Luke A. and Staudte, Robert G.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\DG6KQ97X\\1298644285.html}
}


@online{zotero-88,
  url = {http://projecteuclid.org/download/pdfview_1/euclid.ejs/1298644285},
  urldate = {2016-04-25},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\8C5ZGFTQ\\1298644285.html}
}


@article{yancyLowCarbohydrateKetogenicDiet2004,
  title = {A {{Low}}-{{Carbohydrate}}, {{Ketogenic Diet}} versus a {{Low}}-{{Fat Diet To Treat Obesity}} and {{HyperlipidemiaA Randomized}}, {{Controlled Trial}}},
  volume = {140},
  issn = {0003-4819},
  url = {http://dx.doi.org/10.7326/0003-4819-140-10-200405180-00006},
  doi = {10.7326/0003-4819-140-10-200405180-00006},
  abstract = {As the prevalence of obesity has increased over the past 20 years (1), the difficulties faced by overweight patients and their health care practitioners have become apparent. Fewer than 25\% of Americans who attempt to lose weight actually reduce caloric intake and increase exercise as currently recommended (2). Persons who successfully lose weight have difficulty maintaining their weight loss (3). Therefore, it is not surprising that consumers spend \$33 billion yearly on weight loss products and services in search of effective therapies (2). Because many weight loss interventions are unproven and untested, practitioners often lack information with which to recommend a certain therapy or to monitor a patient once a therapy is chosen.},
  number = {10},
  journaltitle = {Annals of Internal Medicine},
  shortjournal = {Ann Intern Med},
  urldate = {2016-03-23},
  date = {2004-05-18},
  pages = {769-777},
  author = {Yancy, William S., Jr. and Olsen, Maren K. and Guyton, John R. and Bakst, Ronna P. and Westman, Eric C.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\5PV93D8W\\0000605-200405180-00006.pdf}
}


@article{ruthConsumingHypocaloricHigh2013,
  title = {Consuming a Hypocaloric High Fat Low Carbohydrate Diet for 12 Weeks Lowers {{C}}-Reactive Protein, and Raises Serum Adiponectin and High Density Lipoprotein-Cholesterol in Obese Subjects},
  volume = {62},
  issn = {0026-0495},
  url = {http://www.sciencedirect.com/science/article/pii/S0026049513002230},
  doi = {10.1016/j.metabol.2013.07.006},
  abstract = {Objective
High fat, low carbohydrate (HFLC) diets have become popular tools for weight management. We sought to determine the effects of a HFLC diet compared to a low fat high carbohydrate (LFHC) diet on the change in weight loss, cardiovascular risk factors and inflammation in subjects with obesity.
Methods
Obese subjects (29.0–44.6 kg/m2) recruited from Boston Medical Center were randomized to a hypocaloric LFHC (n = 26) or HFLC (n = 29) diet for 12 weeks.
Results
The age range of subjects was 21–62 years. As a percentage of daily calories, the HFLC group consumed 33.5\% protein, 56.0\% fat and 9.6\% carbohydrate and the LFHC group consumed 22.0\% protein, 25.0\% fat and 55.7\% carbohydrate. The change in percent body weight, lean and fat mass, blood pressure, flow mediated dilation, hip:waist ratio, hemoglobin A1C, fasting insulin and glucose, and glucose and insulin response to a 2 h oral glucose tolerance test did not differ (P \&gt; 0.05) between diets after 12 weeks. The HFLC group had greater mean decreases in serum triglyceride (P = 0.07), and hs-CRP (P = 0.03), and greater mean increases in HDL cholesterol (P = 0.004), and total adiponectin (P = 0.045) relative to the LFHC. Secreted adipose tissue adiponectin or TNF-α did not differ after weight loss for either diet.
Conclusions
Relative to the LFHC group, the HFLC group had greater improvements in blood lipids and systemic inflammation with similar changes in body weight and composition. This small-scale study suggests that HFLC diets may be more beneficial to cardiovascular health and inflammation in free-living obese adults compared to LFHC diets.},
  number = {12},
  journaltitle = {Metabolism},
  shortjournal = {Metabolism},
  urldate = {2016-03-23},
  date = {2013-12},
  pages = {1779-1787},
  keywords = {Cardiovascular,Inflammation,Macronutrients,Weight loss},
  author = {Ruth, Megan R. and Port, Ava M. and Shah, Mitali and Bourland, Ashley C. and Istfan, Nawfal W. and Nelson, Kerrie P. and Gokce, Noyan and Apovian, Caroline M.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\EAZQ7QTT\\1-s2.0-S0026049513002230-main.pdf;C:\\Users\\Gleb\\Zotero\\storage\\K3SPX9GM\\login.html}
}


@article{trubyRandomisedControlledTrial2006,
  title = {Randomised Controlled Trial of Four Commercial Weight Loss Programmes in the {{UK}}: Initial Findings from the {{BBC}} “Diet Trials”},
  volume = {332},
  issn = {0959-8138},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1473108/},
  doi = {10.1136/bmj.38833.411204.80},
  shorttitle = {Randomised Controlled Trial of Four Commercial Weight Loss Programmes in the {{UK}}},
  abstract = {Objective To compare the effectiveness of four commercial weight loss diets available to adults in the United Kingdom., Design Six month multicentre randomised unblinded controlled trial., Setting Community based sample of otherwise healthy overweight and obese adults., Interventions Dr Atkins' new diet revolution, Slim-Fast plan, Weight Watchers pure points programme, and Rosemary Conley's eat yourself slim diet and fitness plan., Main outcome measures Weight and body fat changes over six months., Results All diets resulted in significant loss of body fat and weight over six months. Groups did not differ significantly but loss of body fat and weight was greater in all groups compared with the control group. In an intention to treat analysis, average weight loss was 5.9 kg and average fat loss was 4.4 kg over six months. The Atkins diet resulted in significantly higher weight loss during the first four weeks, but by the end was no more or less effective than the other diets., Conclusions Clinically useful weight loss and fat loss can be achieved in adults who are motivated to follow commercial diets for a substantial period. Given the limited resources for weight management in the NHS, healthcare practitioners should discuss with their patients programmes known to be effective., Trial registration Clinical trials NCT00327821.},
  number = {7553},
  journaltitle = {BMJ : British Medical Journal},
  shortjournal = {BMJ},
  urldate = {2016-03-23},
  date = {2006-06-03},
  pages = {1309-1314},
  author = {Truby, Helen and Baic, Sue and {deLooy}, Anne and Fox, Kenneth R and Livingstone, M Barbara E and Logan, Catherine M and Macdonald, Ian A and Morgan, Linda M and Taylor, Moira A and Millward, D Joe},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\6XS3JT3R\\Truby et al. - 2006 - Randomised controlled trial of four commercial wei.pdf},
  eprinttype = {pmid},
  eprint = {16720619},
  pmcid = {PMC1473108}
}


@online{OvidComparisonLowFat,
  title = {Ovid: {{Comparison}} of a {{Low}}-{{Fat Diet}} to a {{Low}}-{{Carbohydrate Diet}} on {{Weight Loss}}, {{Body Composition}}, and {{Risk Factors}} for {{Diabetes}} and {{Cardiovascular Disease}} in {{Free}}-{{Living}}, {{Overweight Men}} and {{Women}}.},
  url = {http://ovidsp.tx.ovid.com.ezproxy.lib.utexas.edu/sp-3.18.0b/ovidweb.cgi?QS2=434f4e1a73d37e8c1650030b04b800f69584fd3b9a3aa717d3e06eb41ceae7a203bd9e6f7170c97146d48a66796132b8b829381f82b1a0f1bad88839cf96dd3a744a01ab9d5c7a26990be86f04e981ef5827caa53dbefbd379f69412c0033069b0510616321b2da9cd01a6048b2405efd5ac91e94ef54ad34b428178f67453ad78fe371a90ba718348aa4939fa3bf09f5246bf3d4ef53946e24dc53adfd8a3aea23f8d1f184213e479646e0ff60474bd31e98642890710e58a753bd0b12abe38768cbb99ea83135a473e4b9dcc8d860ebe6d55cf114af1dd38845fb5d26417683d6ff3becb893d7bc9c2e56f2656e1633bea0ae34dfdf67010bb10c7d5d4a9d1560b347538ea30ed2591c0cd1674c5cbbefd45fe34e92bd13073017f79fd824e4be34f470fdac07ccc4074d6aa9607bd3ed0bd67dd28c98d5c025a2f9897adf8188c2815e967386d917dff630bc815d4a97747cc44bef7ceac0c9bbb6142f53afffe4079c3aacef7c9d9f5c7bcb5674a3afe973074f7d871caf6192e124f5f1f26b7606c4a262afb},
  urldate = {2016-03-23},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\AQ7BXM4G\\ovidweb.html}
}


@article{limLongtermEffectsLow2010,
  title = {Long-Term Effects of a Low Carbohydrate, Low Fat or High Unsaturated Fat Diet Compared to a No-Intervention Control},
  volume = {20},
  issn = {0939-4753},
  url = {http://www.sciencedirect.com/science/article/pii/S0939475309001240},
  doi = {10.1016/j.numecd.2009.05.003},
  abstract = {Background and aim
Very low carbohydrate ad libitum diets have been shown to enhance weight loss without increasing cardiometabolic risk factors but no kilojoule-controlled trials have been conducted relative to no intervention. The aim of this study was to compare the changes in weight and other cardiovascular risk factors in 3 isocaloric energy-restricted diets to no-intervention control after 1 year.
Methods and results
One hundred and thirteen subjects (age 47 ± 10 years, BMI 32 ± 6 kg/m2 with one additional cardiovascular risk factor) were randomly allocated to one of three isocaloric diets (VLC-very low carbohydrate, 60\% fat, 4\% carbohydrate, n = 30; VLF-very low fat, 10\% fat, n = 30; HUF-high unsaturated fat, 30\% fat, n = 30) with intensive support for 3 months followed by minimal support for 12 months compared to a control group (no intervention, n = 23). The estimated weight change was −3.0 ± 0.2 kg for VLC, −2.0 ± 0.1 kg for VLF, −3.7 ± 0.01 kg for HUF and 0.8 ± 0.5 kg for controls (P = 0.065). After correcting for baseline values, decreases in body weight and diastolic blood pressure in the diet groups (−2.9 ± 5.2) were significantly different to the increase in the control group (0.8 ± 5.0) (P \&lt; 0.05). No differences in cardiovascular risk factors were observed between the diet groups.
Conclusion
Significant cardiometabolic risk factor reduction was observed equally with VLC, VLF and HUF diets after 15 months, compared to an exacerbation of risk factors in the control group. At a modest level of adherence, 3 months of intensive support on these dietary patterns confer an improvement in cardiometabolic profile compared to no dietary intervention after 15 months.},
  number = {8},
  journaltitle = {Nutrition, Metabolism and Cardiovascular Diseases},
  shortjournal = {Nutrition, Metabolism and Cardiovascular Diseases},
  urldate = {2016-03-23},
  date = {2010-10},
  pages = {599-607},
  keywords = {High unsaturated fat,Long term,Low carbohydrate diet,Low fat},
  author = {Lim, S. S. and Noakes, M. and Keogh, J. B. and Clifton, P. M.},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\P8HQHWP4\\Lim et al. - 2010 - Long-term effects of a low carbohydrate, low fat o.pdf;C:\\Users\\Gleb\\Zotero\\storage\\4SRFC749\\S0939475309001240.html}
}


@online{FindItUTa,
  title = {Find It@{{UT}}},
  url = {http://te7fv6dm8k.search.serialssolutions.com/?ctx_ver=Z39.88-2004&ctx_enc=info%3Aofi%2Fenc%3AUTF-8&rfr_id=info:sid/summon.serialssolutions.com&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&rft.genre=article&rft.atitle=Weight+loss+with+high+and+low+carbohydrate+1200+kcal+diets+in+free+living+women&rft.jtitle=European+Journal+of+Clinical+Nutrition&rft.au=Lean%2C+M+E+J&rft.au=Han%2C+T+S&rft.au=Prvan%2C+T&rft.au=Richmond%2C+P+R&rft.date=1997-04-01&rft.pub=Nature+Publishing+Group&rft.issn=0954-3007&rft.eissn=1476-5640&rft.volume=51&rft.issue=4&rft.spage=243&rft.externalDocID=20865152&paramdict=en-US},
  urldate = {2016-03-23},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\E6J7QMRE\\te7fv6dm8k.search.serialssolutions.com.html}
}


@online{FindItUTb,
  title = {Find It@{{UT}}},
  url = {http://te7fv6dm8k.search.serialssolutions.com/?ctx_ver=Z39.88-2004&ctx_enc=info%3Aofi%2Fenc%3AUTF-8&rfr_id=info:sid/summon.serialssolutions.com&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&rft.genre=article&rft.atitle=Weight+loss+with+high+and+low+carbohydrate+1200+kcal+diets+in+free+living+women&rft.jtitle=European+Journal+of+Clinical+Nutrition&rft.au=Lean%2C+M+E+J&rft.au=Han%2C+T+S&rft.au=Prvan%2C+T&rft.au=Richmond%2C+P+R&rft.date=1997-04-01&rft.pub=Nature+Publishing+Group&rft.issn=0954-3007&rft.eissn=1476-5640&rft.volume=51&rft.issue=4&rft.spage=243&rft.externalDocID=20865152&paramdict=en-US},
  urldate = {2016-03-23},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\DA3KJC8J\\1600391a.pdf;C:\\Users\\Gleb\\Zotero\\storage\\5USNQ2WZ\\te7fv6dm8k.search.serialssolutions.com.html}
}


@online{FindItUTc,
  title = {Find It@{{UT}}},
  url = {http://te7fv6dm8k.search.serialssolutions.com/?ctx_ver=Z39.88-2004&ctx_enc=info%3Aofi%2Fenc%3AUTF-8&rfr_id=info:sid/summon.serialssolutions.com&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&rft.genre=article&rft.atitle=Comparison+of+the+Atkins%2C+Zone%2C+Ornish%2C+and+LEARN+Diets+for+Change+in+Weight+and+Related+Risk+Factors+Among+Overweight+Premenopausal+Women%3A+The+A+TO+Z+Weight+Loss+Study%3A+A+Randomized+Trial&rft.jtitle=JAMA&rft.au=Christopher+D+Gardner&rft.au=Alexandre+Kiazand&rft.au=Sofiya+Alhassan&rft.au=Soowon+Kim&rft.date=2007-03-07&rft.pub=American+Medical+Association&rft.issn=0098-7484&rft.eissn=1538-3598&rft.volume=297&rft.issue=9&rft.spage=969&rft.externalDocID=1230868011&paramdict=en-US},
  urldate = {2016-03-23},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\XPT2AT32\\00006254-200707000-00019.pdf;C:\\Users\\Gleb\\Zotero\\storage\\VPNVPIP2\\te7fv6dm8k.search.serialssolutions.com.html}
}


@article{buenoVerylowcarbohydrateKetogenicDiet2013,
  title = {Very-Low-Carbohydrate Ketogenic Diet v. Low-Fat Diet for Long-Term Weight Loss: A Meta-Analysis of Randomised Controlled Trials},
  volume = {110},
  issn = {1475-2662},
  url = {http://journals.cambridge.org/article_S0007114513000548},
  doi = {10.1017/S0007114513000548},
  shorttitle = {Very-Low-Carbohydrate Ketogenic Diet v. Low-Fat Diet for Long-Term Weight Loss},
  abstract = {The role of very-low-carbohydrate ketogenic diets (VLCKD) in the long-term management of obesity is not well established. The present meta-analysis aimed to investigate whether individuals assigned to a VLCKD (i.e. a diet with no more than 50 g carbohydrates/d) achieve better long-term body weight and cardiovascular risk factor management when compared with individuals assigned to a conventional low-fat diet (LFD; i.e. a restricted-energy diet with less than 30 \% of energy from fat). Through August 2012, MEDLINE, CENTRAL, ScienceDirect, Scopus, LILACS, SciELO, ClinicalTrials.gov and grey literature databases were searched, using no date or language restrictions, for randomised controlled trials that assigned adults to a VLCKD or a LFD, with 12 months or more of follow-up. The primary outcome was body weight. The secondary outcomes were TAG, HDL-cholesterol (HDL-C), LDL-cholesterol (LDL-C), systolic and diastolic blood pressure, glucose, insulin, HbA1c and C-reactive protein levels. A total of thirteen studies met the inclusion/exclusion criteria. In the overall analysis, five outcomes revealed significant results. Individuals assigned to a VLCKD showed decreased body weight (weighted mean difference − 0·91 (95 \% CI − 1·65, − 0·17) kg, 1415 patients), TAG (weighted mean difference − 0·18 (95 \% CI − 0·27, − 0·08) mmol/l, 1258 patients) and diastolic blood pressure (weighted mean difference − 1·43 (95 \% CI − 2·49, − 0·37) mmHg, 1298 patients) while increased HDL-C (weighted mean difference 0·09 (95 \% CI 0·06, 0·12) mmol/l, 1257 patients) and LDL-C (weighted mean difference 0·12 (95 \% CI 0·04, 0·2) mmol/l, 1255 patients). Individuals assigned to a VLCKD achieve a greater weight loss than those assigned to a LFD in the long term; hence, a VLCKD may be an alternative tool against obesity.},
  number = {07},
  journaltitle = {British Journal of Nutrition},
  urldate = {2016-03-23},
  date = {2013-10},
  pages = {1178--1187},
  author = {Bueno, Nassib Bezerra and de Melo, Ingrid Sofia Vieira and de Oliveira, Suzana Lima and da Rocha Ataide, Terezinha},
  options = {useprefix=true}
}


@article{mansoorEffectsLowcarbohydrateDiets2016,
  title = {Effects of Low-Carbohydrate Diets v. Low-Fat Diets on Body Weight and Cardiovascular Risk Factors: A Meta-Analysis of Randomised Controlled Trials},
  volume = {115},
  issn = {1475-2662},
  url = {http://journals.cambridge.org/article_S0007114515004699},
  doi = {10.1017/S0007114515004699},
  shorttitle = {Effects of Low-Carbohydrate Diets v. Low-Fat Diets on Body Weight and Cardiovascular Risk Factors},
  abstract = {The effects of low-carbohydrate (LC) diets on body weight and cardiovascular risk are unclear, and previous studies have found varying results. Our aim was to conduct a meta-analysis of randomised controlled trials (RCT), assessing the effects of LC diets v. low-fat (LF) diets on weight loss and risk factors of CVD. Studies were identified by searching MEDLINE, Embase and Cochrane Trials. Studies had to fulfil the following criteria: a RCT; the LC diet was defined in accordance with the Atkins diet, or carbohydrate intake of $<$20 \% of total energy intake; twenty subjects or more per group; the subjects were previously healthy; and the dietary intervention had a duration of 6 months or longer. Results from individual studies were pooled as weighted mean difference (WMD) using a random effect model. In all, eleven RCT with 1369 participants met all the set eligibility criteria. Compared with participants on LF diets, participants on LC diets experienced a greater reduction in body weight (WMD –2·17 kg; 95 \% CI –3·36, –0·99) and TAG (WMD –0·26 mmol/l; 95 \% CI –0·37, –0·15), but a greater increase in HDL-cholesterol (WMD 0·14 mmol/l; 95 \% CI 0·09, 0·19) and LDL-cholesterol (WMD 0·16 mmol/l; 95 \% CI 0·003, 0·33). This meta-analysis demonstrates opposite change in two important cardiovascular risk factors on LC diets – greater weight loss and increased LDL-cholesterol. Our findings suggest that the beneficial changes of LC diets must be weighed against the possible detrimental effects of increased LDL-cholesterol.},
  number = {03},
  journaltitle = {British Journal of Nutrition},
  urldate = {2016-03-23},
  date = {2016-02},
  pages = {466--479},
  author = {Mansoor, Nadia and Vinknes, Kathrine J. and Veierød, Marit B. and Retterstøl, Kjetil},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\KGR9VWKK\\S0007114515004699a.pdf;C:\\Users\\Gleb\\Zotero\\storage\\9PK2SHFW\\login.html}
}


@article{fosterRandomizedTrialLowCarbohydrate2003,
  title = {A {{Randomized Trial}} of a {{Low}}-{{Carbohydrate Diet}} for {{Obesity}}},
  volume = {348},
  issn = {0028-4793},
  url = {http://dx.doi.org/10.1056/NEJMoa022207},
  doi = {10.1056/NEJMoa022207},
  abstract = {At any given time, approximately 45 percent of women and 30 percent of men in the United States are trying to lose weight.1 Despite these efforts, the prevalence of obesity has doubled in the past 20 years2 and has become a major public health problem.3 The conventional dietary approach to weight management, recommended by the leading research and medical societies,4–7 is a high-carbohydrate, low-fat, energy-deficit diet. Low-carbohydrate, high-protein, high-fat diets have become increasingly popular, and many best-selling diet books have promoted this approach.8,9 The Atkins diet, originally published in 1973 and again in 1992 and 2002, may be . . .},
  number = {21},
  journaltitle = {New England Journal of Medicine},
  urldate = {2016-03-23},
  date = {2003-05-22},
  pages = {2082-2090},
  author = {Foster, Gary D. and Wyatt, Holly R. and Hill, James O. and McGuckin, Brian G. and Brill, Carrie and Mohammed, B. Selma and Szapary, Philippe O. and Rader, Daniel J. and Edman, Joel S. and Klein, Samuel},
  file = {C:\\Users\\Gleb\\Zotero\\storage\\I5SE5AV9\\Foster et al. - 2003 - A Randomized Trial of a Low-Carbohydrate Diet for .pdf;C:\\Users\\Gleb\\Zotero\\storage\\D57T3V82\\NEJMoa022207.html},
  eprinttype = {pmid},
  eprint = {12761365}
}


@article{fosterWeightMetabolicOutcomes2010,
  title = {Weight and {{Metabolic Outcomes After}} 2 {{Years}} on a {{Low}}-{{Carbohydrate Versus Low}}-{{Fat DietA Randomized Trial}}},
  volume = {153},
  issn = {0003-4819},
  url = {http://dx.doi.org/10.7326/0003-4819-153-3-201008030-00005},
  doi = {10.7326/0003-4819-153-3-201008030-00005},
  abstract = {This article has been corrected. For original version, click â€œOriginal Version (PDF)â€ in column 2.Background: Previous studies comparing low-carbohydrate and low-fat diets have not included a comprehensive behavioral treatment, resulting in suboptimal weight loss.Objective: To evaluate the effects of 2-year treatment with a low-carbohydrate or low-fat diet, each of which was combined with a comprehensive lifestyle modification program.Design: Randomized parallel-group trial. (ClinicalTrials.gov registration number: NCT00143936)Setting: 3 academic medical centers.Patients: 307 participants with a mean age of 45.5 years (SD, 9.7 years) and mean body mass index of 36.1 kg/m2 (SD, 3.5 kg/m2).Intervention: A low-carbohydrate diet, which consisted of limited carbohydrate intake (20 g/d for 3 months) in the form of lowâ€“glycemic index vegetables with unrestricted consumption of fat and protein. After 3 months, participants in the low-carbohydrate diet group increased their carbohydrate intake (5 g/d per wk) until a stable and desired weight was achieved. A low-fat diet consisted of limited energy intake (1200 to 1800 kcal/d;Â
