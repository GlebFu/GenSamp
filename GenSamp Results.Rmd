---
title             : "Assessing sampling methods for generalization from RCTs: Modeling recruitment and participation"
shorttitle        : "Assessing sampling methods for generalization from RCTs"

author:
  - name          : "Gleb Furman"
    affiliation   : "1"
    # corresponding : yes    # Define only one corresponding author
    # address       : "Postal address"
    # email         : "Gleb.Furman@gmail.com"
  - name          : "James E. Pustejovsky"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Texas at Austin"
#   - id            : "2"
#     institution   : "Konstanz Business School"

# author_note: |
#   Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

#   Enter author note here.

abstract: |
    <!-- In order for educational research to be informative to policy makers, studies must be designed to make robust estimates of causal effects at the population level. Large scale multi-site randomized trials (MRT) often rely on vague convenience sampling methodology when recruiting districts and schools, resulting in relatively homogeneous samples that may differ greatly from the intended population of interest. Retrospective methods that quantify and statistically adjust for those differences are prosmising but have limited effect when the sample differs greatly from the population. Designing sampling methods that focus on generalizability may be a more ffective but costly solution, but limited methodological research has been performed to examine their effectiveness in the eduational context. This paper examines one promising method, stratified balanced sampling (SBS), in the context of recruiting a representative sample of schools for a large scale MRT. Using simulations based on real data, we compare SBS to stratified and unstratified versions of convenince sampling and probability sampling. Several models for generating school participation and emulating convenience sampling are proposed. Results indicate that SBS and stratified random sampling (SRS) result in highly generalizable samples. These methods are extremely costly to implement, however, especially when the population average willingness to participate is low. Stratified convenience sampling (SCS) is a potential compromise. -->

# keywords          : "keywords"
# wordcount         : "X"

bibliography      : ["references.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, cache = F, eval = T)

```

```{r load.packages, include = FALSE}
library(papaja)
library(tidyverse)

rm(list = ls())
```


# Results


## Generalizability

```{r results-data, cache = F}

load("Paper Data/Result Data.rdata")

```

Figure \@ref(fig:fig-SMD-by-Var) displays the average SMD between the samples and the population for each covariate and at each population participation rate resulting from each sampling method. The dotted horizontal line indicates a cutoff of .25, where SMDs above that indicate large differences between the sample and population for that covariate. Stratified methods consistently performed better than unstratified methods. SBS generally performed as well as or better than SRS. URS often resulted in highly unrepresenative samples except in cases where population participation rates were extremely high.

Figure \@ref(fig:fig-avg-Bindex) displays the average $B$-index for each method across participation rates. At population participation rates of 60% and higher, all methods resulted in similarly generalizable samples. However, at lower rates only SBS and SRS consistantly generated highly generalizable samples. SCS and URS performed equally, while UCS resulted in relatively less generalizable samples.

```{r fig-SMD-by-Var, results = "asis", fig.cap = "Averge Standardized Mean Differences between sample and population", eval = T}
sSMDplot %>%
  filter(Group == "sampled") %>%
  ggplot(aes(x = sch.RR, y = sim_SMD, color = Sampling, linetype = Clustering, group = sample)) +
  # geom_point() +
  geom_line() +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = .25, linetype = "dashed") +
  facet_wrap( ~ Variable, scales = "free_y") +
  theme_apa(box = F) +
  labs(y = "Mean SMD",
       x = "Population Participation Rate")

```


```{r fig-avg-Bindex, results = "asis", fig.cap = "Averge $B$-index across participation rates by sampling method", eval = T}

avg_Bindex %>%
  ggplot(aes(x = sch.RR, y = M, color = Sampling, linetype = Clustering)) +
  geom_line() +
  labs(y = "Mean B-index",
       x = "Population Participation Rate") +
  theme_apa()


```




```{r fig-avg-SMD, results = "asis", fig.cap = "Average absolute SMD across covariates", eval = F}

sSMDplot %>%
  filter(Group == "sampled") %>%
  ggplot(aes(x = sample, y = sim_SMD, group = sample, fill = Sampling, linetype = Clustering)) +
  geom_boxplot() +
  geom_line() +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = .25, linetype = "dashed") +
  # facet_grid(dist.RR ~ sch.RR, scales = "free_y") +
  theme_apa(box = T) +
  # scale_fill_brewer(type = "seq", palette = 4, guide=FALSE) +
  # scale_color_brewer(type = "qual", palette = 5)  +
  theme(legend.position = "none",
        panel.spacing = unit(2, "lines"),
        text = element_text(size=20),
        legend.title = element_text(size=15)) +
  labs(x = "Sampling Method", y = "Absolute SMD")
```

## Feasibility

Figure \@ref(fig:fig-units-contacted) reports the average number of schools that needed to be contacted before a full sample of $N = 60$ schools was selected. At higher participation rates differences between methods were negligibile. However, as participation rates decreased the disparity between the methods became more apparent. Overall, UCS required the least "effort" to recruit a full sample, followed by URS and SCS, SRS, and finally SBS. Figure \@ref(fig:fig-response-rates) plots the participation rates of schools approached for recruitment against the population participation rates. As expected, URS participation rates reflected those in the population. Both UCS and SCS resulted in higher participation rates, while SRS and SBS resulted in lower participation rates. 
```{r fig-responses, results = "asis", fig.cap = "Sampling statistics", eval = F}
samplot %>%
  gather(key = measure, value = value, -sample, -sch.RR, -Sampling, -Clustering) %>%
  mutate(level = str_split(measure, "_", simplify = T)[,1],
         measure =  str_split(measure, "_", simplify = T)[,2]) %>%
  filter(level == "sch") %>%
  ggplot(aes(x = sch.RR, y = value, group = sample, color = Sampling, linetype = Clustering)) +
  geom_point() +
  geom_line() +
  facet_wrap( ~ measure, scales = "free_y") +
  expand_limits(y=0) +
  theme_apa(box = T)
```

```{r fig-units-contacted, results = "asis", fig.cap = "Averge number of schools contacted to achieve N = 60", eval = T}
contact_data <- samplot %>%
  gather(key = measure, value = value, -sample, -sch.RR, -Sampling, -Clustering) %>%
  mutate(level = str_split(measure, "_", simplify = T)[,1],
         measure =  str_split(measure, "_", simplify = T)[,2]) %>%
  filter(measure == "contacted") %>%
  mutate(level = ifelse(level == "sch", "Schools", "Districts"))

contact_data %>%
  ggplot(aes(x = sch.RR, y = value, group = sample, color = Sampling, linetype = Clustering)) +
  geom_point() +
  geom_line() +
  expand_limits(y=0) +
  # theme_apa(box = T) +
  # scale_fill_brewer(type = "seq", palette = 4) +
  # scale_color_brewer(type = "qual", palette = 3)  +
  theme(legend.position = "bottom",
        panel.spacing = unit(2, "lines"),
        # text = element_text(size=20),
        # legend.title = element_text(size=15),
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Population Response Rate", y = "Units Contacted") +
  # scale_y_log10() +â—™
  theme_apa()
```

```{r fig-response-rates, results = "asis", fig.cap = "Recruitment response rates for each sampling method", eval = T}
response_rate_data <- samplot %>%
  gather(key = measure, value = value, -sample, -sch.RR, -Sampling, -Clustering) %>%
  mutate(level = str_split(measure, "_", simplify = T)[,1],
         measure =  str_split(measure, "_", simplify = T)[,2]) %>%
  filter(measure == "RR") %>%
  mutate(level = ifelse(level == "sch", "Schools", "Districts"))

response_rate_data %>%
  ggplot(aes(x = sch.RR, y = value, group = sample, color = Sampling, linetype = Clustering)) +
  geom_point() +
  geom_line() +
  expand_limits(y=0) +
  # theme_apa(box = T) +
  # scale_fill_brewer(type = "seq", palette = 4) +
  # scale_color_brewer(type = "qual", palette = 3)  +
  theme(legend.position = "bottom",
        panel.spacing = unit(2, "lines"),
        # text = element_text(size=20),
        # legend.title = element_text(size=15),
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Population Response Rate", y = "Recruitment Response Rate") +
  theme_apa()
```


\newpage

# Discussion
The main goal of this study was to lay a groundwork for exploring the effectiveness and feasibility of sampling methods in the educational context. Our work uncovered several limitations in designing sampling and participation models. Our sampling method made several assumptions about researcher and recruiter behavior in selecting sample. First, that recruiters always prioritize schools that are most likely to participate. In fact, many other factors play a role such as proximity of sample units to the researcher and to each other, existing relationships between the recruiters and the sample units, and other researcher sampling biases. Second, that recruiters have approximiate knowledge of how likely a sampled unit is to participate. Though researchers may speculate about units that are more willing to participate (schools in larger urban distrits) and prioritize those, it is not likely that estimate willingness as well as we have simulated. Given this, it is possible that the "feasibility" of the convenience methods is overestimated.
That said, our participation model is also probably highly innacurate. The parameters in our response generating model are based off of a study that examined the difference between schools participating in large-scale randomized control trials (RCT) and the population of schools. However, these RCTs themsevles typically typically rely on some form of convenience sampling. In that sense our parameters reflect participation rates of schools that are likely to participate in RCTs, rather than the full population of schools. Furthermore, the decision of whether a school participates in such a study is multi-leveled. Generally, districts serve as gatekeepers and require research requests to be submitted and approved before recruitment can begin. If the request is denied, no schools within that district may be recruited. If approved, schools may be contacted individually, however the decision to participate may rest with administrators, or they may be passed on to teachers most affected by the stuydy.


# References

```{r create_r-references}
r_refs(file = "references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
